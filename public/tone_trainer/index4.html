<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
      Pitch (Tone) Analyzer for Mandarin Practice - emira.ga (Emir Bosnian)
    </title>
    <link href="./output.css" rel="stylesheet" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
      }
      /* Style for the canvas to make it responsive and sharp */
      canvas {
        width: 100%;
        height: 300px;
        background-color: #111827; /* bg-gray-900 */
        border-radius: 0.5rem;
        image-rendering: -moz-crisp-edges;
        image-rendering: -webkit-crisp-edges;
        image-rendering: pixelated;
        image-rendering: crisp-edges;
      }
      /* Custom styles for range sliders */
      input[type="range"] {
        -webkit-appearance: none;
        appearance: none;
        width: 100%;
        height: 8px;
        background: #4b5563; /* bg-gray-600 */
        border-radius: 5px;
        outline: none;
        opacity: 0.7;
        transition: opacity 0.2s;
      }
      input[type="range"]:hover {
        opacity: 1;
      }
      input[type="range"]::-webkit-slider-thumb {
        -webkit-appearance: none;
        appearance: none;
        width: 20px;
        height: 20px;
        background: #3b82f6; /* bg-blue-500 */
        cursor: pointer;
        border-radius: 50%;
      }
      input[type="range"]::-moz-range-thumb {
        width: 20px;
        height: 20px;
        background: #3b82f6; /* bg-blue-500 */
        cursor: pointer;
        border-radius: 50%;
      }
    </style>
  </head>
  <body
    class="bg-gray-800 text-gray-200 flex-col items-center justify-center min-h-screen p-4"
  >
    <div class="w-full max-w-4xl mx-auto">
      <!-- Spectrogram Canvas with YIN Pitch Overlay -->
      <div
        id="dropZone"
        class="w-full bg-gray-900 rounded-lg shadow-lg p-2 relative transition-all duration-200"
      >
        <div class="relative">
          <canvas id="spectrogramCanvas"></canvas>
          <canvas
            id="yinPitchCanvas"
            class="absolute top-0 left-0 pointer-events-none"
            style="background: transparent"
          ></canvas>
          <div
            id="progressLine"
            class="absolute top-0 w-0.5 bg-white opacity-90 pointer-events-none hidden"
            style="height: 100%; left: 0%; transition: left 0.1s linear"
          ></div>
          <div
            id="dropOverlay"
            class="absolute inset-0 bg-blue-500/60 border-4 border-dashed border-blue-400 flex items-center justify-center rounded-lg hidden"
          >
            <div class="text-center">
              <svg
                class="w-16 h-16 mx-auto mb-4 text-blue-300"
                fill="none"
                stroke="currentColor"
                viewBox="0 0 24 24"
              >
                <path
                  stroke-linecap="round"
                  stroke-linejoin="round"
                  stroke-width="2"
                  d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12"
                ></path>
              </svg>
              <p class="text-blue-100 text-xl font-medium">
                Drop audio file here
              </p>
              <p class="text-blue-200 text-sm mt-2">
                Supported formats: MP3, WAV, OGG, M4A
              </p>
            </div>
          </div>
        </div>
        <div
          id="yinPitchLoadingOverlay"
          class="absolute inset-0 bg-gray-900/80 flex items-center justify-center rounded-lg hidden"
        >
          <div class="text-center">
            <div
              class="animate-spin rounded-full h-8 w-8 border-b-2 border-purple-500 mx-auto mb-2"
            ></div>
            <p class="text-gray-300 text-sm">Computing YIN pitch...</p>
          </div>
        </div>
        <!-- Play Button -->
        <div id="playButton" class="flex justify-center mt-3">
          <button
            id="playStopButton"
            onclick="togglePlayStop()"
            class="flex items-center justify-center w-12 h-12 bg-blue-600 hover:bg-blue-500 rounded-full transition-colors duration-200 shadow-lg"
            title="Play audio"
          >
            <svg
              id="playIcon"
              class="w-6 h-6 text-white ml-0.5"
              fill="currentColor"
              viewBox="0 0 24 24"
            >
              <path d="M8 5v14l11-7z" />
            </svg>
            <svg
              id="stopIcon"
              class="w-6 h-6 text-white hidden"
              fill="currentColor"
              viewBox="0 0 24 24"
            >
              <rect x="6" y="6" width="12" height="12" />
            </svg>
          </button>
          <div class="p-3.5">
            or press
            <kbd
              class="px-2 py-1.5 text-xs font-semibold text-gray-800 bg-gray-100 border border-gray-200 rounded-lg"
              >Enter</kbd
            >
            to play, hold
            <kbd
              class="px-2 py-1.5 text-xs font-semibold text-gray-800 bg-gray-100 border border-gray-200 rounded-lg"
              >Space</kbd
            >
            to record, or drag & drop an audio file.
          </div>
        </div>
      </div>

      <!-- Status Message -->
      <div
        id="status"
        class="text-center mb-4 p-3 rounded-lg bg-gray-700 transition-all duration-300"
      >
        <div class="flex items-center justify-center">
          <div
            id="statusSpinner"
            class="animate-spin rounded-full h-4 w-4 border-b-2 border-blue-300 mr-2 hidden"
          ></div>
          <p id="instructions" class="text-lg font-medium text-blue-300">
            Loading...
          </p>
        </div>
      </div>

      <!-- Display Controls -->
      <div
        id="controls"
        class="mt-6 mb-2 grid grid-cols-2 md:grid-cols-3 gap-6 bg-gray-700/50 p-6 rounded-lg"
      >
        <div>
          <label
            for="brightness"
            class="block mb-2 text-sm font-medium text-gray-300"
            >Brightness</label
          >
          <input
            type="range"
            id="brightness"
            min="-150"
            max="100"
            class="w-full"
          />
          <div
            class="text-xs text-gray-400 text-center mt-1"
            id="brightnessValue"
          ></div>
        </div>
        <div>
          <label
            for="contrast"
            class="block mb-2 text-sm font-medium text-gray-300"
            >Contrast</label
          >
          <input
            type="range"
            id="contrast"
            min="0.0"
            max="5.0"
            step="0.1"
            class="w-full"
          />
          <div
            class="text-xs text-gray-400 text-center mt-1"
            id="contrastValue"
          ></div>
        </div>
        <div>
          <label
            for="colorScheme"
            class="block mb-2 text-sm font-medium text-gray-300"
            >Color Scheme</label
          >
          <select
            id="colorScheme"
            class="bg-gray-600 border border-gray-500 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-1"
          >
            <option value="viridis">Viridis</option>
            <option value="plasma">Plasma</option>
            <option value="hot">Hot</option>
            <option value="grayscale">Grayscale</option>
          </select>
        </div>
      </div>

      <!-- Algorithm Controls -->
      <div id="yinControlsSection" class="mt-4 hidden">
        <!-- YIN Controls -->
        <div class="mb-2">
          <h4 class="text-yellow-400 text-sm font-medium mb-2">
            YIN Algorithm parameters:
          </h4>

          <div
            id="yinControls"
            class="grid grid-cols-2 md:grid-cols-3 gap-4 bg-gray-700/50 p-4 rounded-lg"
          >
            <!---->
            <div class="flex items-center">
              <input
                type="checkbox"
                id="yinFft"
                class="w-4 h-4 text-blue-600 bg-gray-700 border-gray-600 rounded focus:ring-blue-500"
              />
              <label for="yinFft" class="ml-2 text-xs font-medium text-gray-300"
                >Use faster FFT algorithm</label
              >
            </div>

            <div>
              <label
                for="yinFrameSize"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Frame Size</label
              >
              <select
                id="yinFrameSize"
                class="bg-gray-600 border border-gray-500 text-white text-xs rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-1"
              >
                <option value="128">128</option>
                <option value="256">256</option>
                <option value="512">512</option>
                <option value="1024">1024</option>
                <option value="2048">2048</option>
                <option value="4096">4096</option>
              </select>
            </div>
            <div>
              <label
                for="yinHopSize"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Hop Size</label
              >
              <select
                id="yinHopSize"
                class="bg-gray-600 border border-gray-500 text-white text-xs rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-1"
              >
                <option value="16">16</option>
                <option value="32">32</option>
                <option value="64">64</option>
                <option value="128">128</option>
                <option value="256">256</option>
                <option value="512">512</option>
                <option value="1024">1024</option>
                <option value="2048">2048</option>
                <option value="4096">4096</option>
              </select>
            </div>
            <div>
              <label
                for="yinThreshold"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Threshold</label
              >
              <input
                type="range"
                id="yinThresholdSlider"
                min="0.05"
                max="0.9"
                step="0.01"
                class="w-full"
              />
              <div
                class="text-xs text-gray-400 text-center mt-1"
                id="yinThresholdValue"
              ></div>
            </div>
            <div>
              <label
                for="yinMinFreq"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Min Freq (Hz)</label
              >
              <input
                type="range"
                id="yinMinFreqSlider"
                min="10"
                max="200"
                step="5"
                class="w-full"
              />
              <div
                class="text-xs text-gray-400 text-center mt-1"
                id="yinMinFreqValue"
              ></div>
            </div>
            <div>
              <label
                for="yinMaxFreq"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Max Freq (Hz)</label
              >
              <input
                type="range"
                id="yinMaxFreqSlider"
                min="100"
                max="1000"
                step="10"
                class="w-full"
              />
              <div
                class="text-xs text-gray-400 text-center mt-1"
                id="yinMaxFreqValue"
              ></div>
            </div>

            <div class="flex items-center">
              <input
                type="checkbox"
                id="yinInterpolation"
                class="w-4 h-4 text-blue-600 bg-gray-700 border-gray-600 rounded focus:ring-blue-500"
              />
              <label
                for="yinInterpolation"
                class="ml-2 text-xs font-medium text-gray-300"
                >Parabolic Interpolation</label
              >
            </div>

            <!---->
          </div>
        </div>
      </div>
      <!---->
    </div>

    <!---->
    <script src="audio.js"></script>
    <script>
      // Preloaded audio data defined in public/tone_trainer/audio.js
      const PRELOADED_AUDIO_DATA = window.PRELOADED_AUDIO_DATA;

      // DOM Elements
      const instructions = document.getElementById("instructions");
      const statusDiv = document.getElementById("status");
      const statusSpinner = document.getElementById("statusSpinner");
      const canvas = document.getElementById("spectrogramCanvas");
      const canvasCtx = canvas.getContext("2d");
      const progressLine = document.getElementById("progressLine");
      const yinPitchCanvas = document.getElementById("yinPitchCanvas");
      const yinPitchCanvasCtx = yinPitchCanvas.getContext("2d");
      const controls = document.getElementById("controls");
      const playButton = document.getElementById("playButton");
      const playStopButton = document.getElementById("playStopButton");
      const playIcon = document.getElementById("playIcon");
      const stopIcon = document.getElementById("stopIcon");
      const colorSchemeSelect = document.getElementById("colorScheme");
      const brightnessSlider = document.getElementById("brightness");
      const contrastSlider = document.getElementById("contrast");
      const yinPitchLoadingOverlay = document.getElementById(
        "yinPitchLoadingOverlay",
      );
      const yinControlsSection = document.getElementById("yinControlsSection");
      const dropZone = document.getElementById("dropZone");
      const dropOverlay = document.getElementById("dropOverlay");

      // Audio & State Variables
      let audioContext;
      let mediaRecorder;
      let isRecording = false;
      let audioChunks = [];
      let spectrogramData = [];
      let yinData = [];
      let lastAudioBuffer = null;
      let currentAudioSource = null;
      let isPlaying = false;

      // Visualization Settings
      let settings = {
        colorScheme: "viridis",
        brightness: -50,
        contrast: 1.5,
      };

      // YIN Algorithm Parameters
      let yinParams = {
        frameSize: 2048, // Window size for analysis
        hopSize: 128, // Step size between frames
        threshold: 0.6, // Absolute threshold for period detection
        minFreq: 30, // Minimum frequency to consider (Hz)
        maxFreq: 300, // Maximum frequency to consider (Hz)
        interpolation: true, // Enable parabolic interpolation
        fft: true, // use FFT algorithm
      };

      // --- ANALYSIS CONSTANTS (EDITED FOR HIGHER RESOLUTION) ---
      // Increased FFT_SIZE for better frequency (vertical) resolution.
      const FFT_SIZE = 4096 * 2;
      // The maximum frequency (in Hz) to display. This focuses the view on the vocal range.
      const MAX_FREQ_HZ = 1300;
      // is about how often we do the analysis. The system collects audio into a buffer, and every time the buffer is full, it runs the analysis.
      const BUFFER_SIZE = 256;

      // --- UI CONSTANTS ---
      // Progress line update interval in milliseconds
      const PROGRESS_UPDATE_INTERVAL_MS = 50;
      // Maximum vertical jump threshold as percentage of canvas height for YIN pitch chart
      const YIN_MAX_JUMP_THRESHOLD_PERCENT = 0.1;
      // Pitch point radius in pixels for YIN pitch visualization
      const YIN_PITCH_POINT_RADIUS = 3;
      // Line width for YIN pitch chart
      const YIN_PITCH_LINE_WIDTH = 3;

      // --- COLOR MAPS ---
      const COLOR_MAPS = {
        viridis: [
          [68, 1, 84],
          [72, 40, 120],
          [62, 74, 137],
          [49, 104, 142],
          [38, 130, 142],
          [31, 158, 137],
          [53, 183, 121],
          [109, 205, 89],
          [180, 222, 44],
          [253, 231, 37],
        ],
        plasma: [
          [13, 8, 135],
          [72, 1, 163],
          [120, 1, 168],
          [163, 29, 151],
          [201, 62, 122],
          [230, 99, 90],
          [249, 139, 64],
          [254, 183, 43],
          [240, 226, 33],
        ],
        hot: [
          [0, 0, 0],
          [255, 0, 0],
          [255, 255, 0],
          [255, 255, 255],
        ],
        grayscale: [
          [0, 0, 0],
          [255, 255, 255],
        ],
      };

      function interpolateColor(c1, c2, factor) {
        const result = c1.slice();
        for (let i = 0; i < 3; i++) {
          result[i] = Math.round(result[i] + factor * (c2[i] - result[i]));
        }
        return result;
      }

      function getColor(value, schemeName) {
        const map = COLOR_MAPS[schemeName];
        const scaledValue = (value / 255) * (map.length - 1);
        const colorIndex = Math.floor(scaledValue);
        const factor = scaledValue - colorIndex;

        if (colorIndex >= map.length - 1) {
          return map[map.length - 1];
        }
        return interpolateColor(map[colorIndex], map[colorIndex + 1], factor);
      }

      // --- YIN ALGORITHM IMPLEMENTATION ---
      function yinDifferenceFunction(buffer) {
        const bufferSize = buffer.length;
        const differenceFunction = new Array(bufferSize / 2);

        // Step 1: Difference function d_t(τ) = Σ(x_j - x_{j+τ})²
        for (let tau = 0; tau < bufferSize / 2; tau++) {
          let sum = 0;
          for (let j = 0; j < bufferSize / 2; j++) {
            const delta = buffer[j] - buffer[j + tau];
            sum += delta * delta;
          }
          differenceFunction[tau] = sum;
        }

        return differenceFunction;
      }

      /**
       * Calculates the YIN difference function using an FFT-based approach
       * for improved performance.
       * @param buffer The audio frame buffer.
       * @returns The difference function array.
       */
      function yinDifferenceFunctionFFT_SomeIssues(buffer) {
        const bufferSize = buffer.length;
        const halfBufferSize = bufferSize / 2;
        const differenceFunction = new Array(halfBufferSize).fill(0);

        // 1. Pad buffer to next power of 2 for FFT
        const fftSize = 1 << Math.ceil(Math.log2(bufferSize));
        const fft = new FFTJS(fftSize);

        const paddedBuffer = new Float32Array(fftSize);
        paddedBuffer.set(buffer);

        // 2. Compute FFT
        const fftResult = fft.createComplexArray();
        fft.realTransform(fftResult, paddedBuffer);

        // 3. Calculate Power Spectral Density (PSD)
        const psd = new Float32Array(fftSize);
        for (let i = 0; i < fftSize; i += 2) {
          const real = fftResult[i];
          const imag = fftResult[i + 1];
          psd[i / 2] = real * real + imag * imag;
        }

        // 4. Compute IFFT of PSD to get autocorrelation
        const autocorrelationComplex = fft.createComplexArray();
        // We need to transform the real-valued PSD into a complex format for IFFT
        for (let i = 0; i < psd.length; i++) {
          autocorrelationComplex[i * 2] = psd[i];
          autocorrelationComplex[i * 2 + 1] = 0;
        }
        const autocorrelationResult = fft.createComplexArray();
        fft.inverseTransform(autocorrelationResult, autocorrelationComplex);

        // 5. Calculate the difference function from autocorrelation
        // d(τ) ≈ 2 * (r(0) - r(τ))
        // We only need the real part of the autocorrelation
        const r0 = autocorrelationResult[0];
        for (let tau = 1; tau < halfBufferSize; tau++) {
          differenceFunction[tau] = r0 - autocorrelationResult[tau * 2];
        }

        // The difference function at tau=0 is 0
        differenceFunction[0] = 0;

        return differenceFunction;
      }

      /**
       * Calculates the YIN difference function using a corrected FFT-based approach
       * with sufficient zero-padding for linear correlation.
       */
      function yinDifferenceFunctionFFT_Fixed(buffer) {
        const N = buffer.length; // Original buffer size
        const halfBufferSize = N / 2;
        const differenceFunction = new Array(halfBufferSize).fill(0); // 1. Correct Zero-Padding: Pad to next power of 2 >= 2*N - 1

        const requiredSize = 2 * N - 1;
        const fftSize = 1 << Math.ceil(Math.log2(requiredSize)); // M: Smallest power of 2 >= 2*N - 1
        // Initialize the FFT library with the new, larger size
        const fft = new FFTJS(fftSize); // Create a padded buffer (padded with zeros)

        const paddedBuffer = new Float32Array(fftSize);
        paddedBuffer.set(buffer); // 2. Compute FFT

        const fftResult = fft.createComplexArray();
        fft.realTransform(fftResult, paddedBuffer); // 3. Calculate Power Spectral Density (PSD)

        const psd = new Float32Array(fftSize / 2); // PSD is symmetric, only need first half
        for (let i = 0; i < fftSize; i += 2) {
          const real = fftResult[i];
          const imag = fftResult[i + 1];
          psd[i / 2] = real * real + imag * imag;
        } // 4. Compute IFFT of PSD to get autocorrelation

        const autocorrelationComplex = fft.createComplexArray(); // Transform the real-valued PSD into a complex format for IFFT
        for (let i = 0; i < psd.length; i++) {
          autocorrelationComplex[i * 2] = psd[i];
          autocorrelationComplex[i * 2 + 1] = 0;
        }
        const autocorrelationResult = fft.createComplexArray();
        fft.inverseTransform(autocorrelationResult, autocorrelationComplex); // 5. Calculate the difference function from autocorrelation
        // The IFFT results are scaled by 1/fftSize. This should be accounted for.

        const scaleFactor = 1.0 / fftSize; // r(0) is the first (real) element, scaled
        const r0 = autocorrelationResult[0] * scaleFactor;
        differenceFunction[0] = 0; // d(0) is 0

        for (let tau = 1; tau < halfBufferSize; tau++) {
          // r(tau) is the real part of the tau-th element, scaled
          const r_tau = autocorrelationResult[tau * 2] * scaleFactor; // Use the approximation d(τ) ≈ 2 * (r(0) - r(τ))
          differenceFunction[tau] = 2.0 * (r0 - r_tau);
        }

        return differenceFunction;
      }

      function yinCumulativeMeanNormalizedDifference(differenceFunction) {
        const cmndf = new Array(differenceFunction.length);
        cmndf[0] = 1;

        // Step 2: Cumulative mean normalized difference function
        // d'_t(τ) = { 1 if τ = 0
        //           { d_t(τ) / ((1/τ) * Σ_{j=1}^τ d_t(j)) if τ ≠ 0
        let runningSum = 0;
        for (let tau = 1; tau < differenceFunction.length; tau++) {
          runningSum += differenceFunction[tau];
          cmndf[tau] = differenceFunction[tau] / (runningSum / tau);
        }

        return cmndf;
      }

      function yinAbsoluteThreshold_issues(cmndf, threshold) {
        // Step 3: Absolute threshold
        // Find the first minimum below the threshold
        for (let tau = 2; tau < cmndf.length; tau++) {
          if (cmndf[tau] < threshold) {
            // Check if this is a local minimum
            while (tau + 1 < cmndf.length && cmndf[tau + 1] < cmndf[tau]) {
              tau++;
            }
            return tau;
          }
        }
        return -1; // No period found
      }

      /**
       * Finds the best pitch candidate (tau) by applying the absolute threshold
       * and then searching for the true local minimum.
       * @param cmndf The Cumulative Mean Normalized Difference Function.
       * @param threshold The YIN absolute threshold (e.g., 0.1 to 0.25).
       * @returns The index tau of the minimum below threshold, or -1.
       */
      function yinAbsoluteThreshold(cmndf, threshold) {
        // Start search at tau=2, as tau=0 is always 0 and tau=1 is often too small
        for (let tau = 2; tau < cmndf.length - 1; tau++) {
          // 1. Check if the value is BELOW the absolute threshold
          if (cmndf[tau] < threshold) {
            // 2. Check if this is a local minimum, or if we need to search for one.
            // The key is to find the minimum *within the valley* that crossed the threshold.
            let minTau = tau; // Search forward while the difference function is still decreasing.
            // This ensures we land on the true minimum point of the local dip.
            while (
              minTau + 1 < cmndf.length &&
              cmndf[minTau + 1] < cmndf[minTau]
            ) {
              minTau++;
            } // Return the index of the true local minimum found.
            return minTau;
          }
        }
        return -1; // No period found
      }

      function yinParabolicInterpolation(cmndf, tauEstimate) {
        // Step 4: Parabolic interpolation for better accuracy
        if (tauEstimate < 1 || tauEstimate >= cmndf.length - 1) {
          return tauEstimate;
        }

        const s0 = cmndf[tauEstimate - 1];
        const s1 = cmndf[tauEstimate];
        const s2 = cmndf[tauEstimate + 1];

        // Parabolic interpolation formula
        const betterTau = tauEstimate + (s2 - s0) / (2 * (2 * s1 - s2 - s0));
        return betterTau;
      }

      function performYinAnalysis(audioBuffer, frameSize, hopSize) {
        // Use parameters from yinParams if not provided
        frameSize = frameSize || yinParams.frameSize;
        hopSize = hopSize || yinParams.hopSize;

        const sampleRate = audioBuffer.sampleRate;
        const audioData = audioBuffer.getChannelData(0);
        const yinResults = [];

        // Performance tracking
        const analysisStartTime = performance.now();
        let frameCount = 0;

        const useDifferenceFunction = yinParams.fft
          ? yinDifferenceFunctionFFT_Fixed
          : yinDifferenceFunction;

        // Process audio in overlapping frames
        for (let i = 0; i <= audioData.length - frameSize; i += hopSize) {
          const frame = audioData.slice(i, i + frameSize);

          // Step 1: Difference function
          const differenceFunction = useDifferenceFunction(frame);
          frameCount++;

          // Step 2: Cumulative mean normalized difference function
          const cmndf =
            yinCumulativeMeanNormalizedDifference(differenceFunction);

          // Step 3: Absolute threshold
          let tauEstimate = yinAbsoluteThreshold(cmndf, yinParams.threshold);

          let pitch = 0;
          let confidence = 0;

          if (tauEstimate > 0) {
            // Step 4: Parabolic interpolation (if enabled)
            const betterTau = yinParams.interpolation
              ? yinParabolicInterpolation(cmndf, tauEstimate)
              : tauEstimate;

            // Convert tau to frequency
            pitch = sampleRate / betterTau;

            // Confidence is inverse of CMNDF value at the estimated tau
            confidence = 1 - cmndf[Math.round(betterTau)];

            // Filter out unrealistic pitches using dynamic parameters
            if (pitch < yinParams.minFreq || pitch > yinParams.maxFreq) {
              pitch = 0;
              confidence = 0;
            }
          }

          yinResults.push({
            pitch: pitch,
            confidence: confidence,
          });
        }

        // Store performance data
        const totalTime = performance.now() - analysisStartTime;
        console.log(
          `YIN Performance:${yinParams.fft ? " FFT" : ""} Total=${totalTime.toFixed(1)}ms, Frames=${frameCount}`,
        );

        return yinResults;
      }

      // --- HELPER FUNCTIONS ---
      // DOM visibility helpers
      function show(element) {
        element.classList.remove("hidden");
      }

      function hide(element) {
        element.classList.add("hidden");
      }

      // Status message helpers
      function setStatus(message, options = {}) {
        const {
          backgroundColor = null,
          isLoading = false,
          spinnerColor = "border-blue-300",
        } = options;

        // Update message text
        instructions.textContent = message;

        // Show/hide spinner
        if (isLoading) {
          // Update spinner color
          replaceClasses(
            statusSpinner,
            ["border-blue-300", "border-purple-300", "border-green-300"],
            [spinnerColor],
          );
          show(statusSpinner);
        } else {
          hide(statusSpinner);
        }

        show(statusDiv);

        if (backgroundColor) {
          statusDiv.style.backgroundColor = backgroundColor;
        }
      }

      function hideStatus() {
        hide(statusDiv);
      }

      // Controls visibility
      function showControls() {
        show(controls);
        show(playButton);
        show(yinControlsSection);
      }

      // Progress line helpers
      function showProgressLine() {
        show(progressLine);
        progressLine.style.left = "0%";
      }

      function hideProgressLine() {
        hide(progressLine);
      }

      function updateProgressLine(percentage) {
        progressLine.style.left = percentage + "%";
      }

      // Text content helpers
      function setText(elementId, text) {
        document.getElementById(elementId).textContent = text;
      }

      // Class manipulation helpers
      function replaceClasses(element, removeClasses, addClasses) {
        element.classList.remove(...removeClasses);
        element.classList.add(...addClasses);
      }

      // Play/Stop button state management
      function showPlayingState() {
        hide(playIcon);
        show(stopIcon);
        playStopButton.title = "Stop audio";
        replaceClasses(
          playStopButton,
          ["bg-blue-600", "hover:bg-blue-500"],
          ["bg-red-600", "hover:bg-red-500"],
        );
      }

      function showStoppedState() {
        show(playIcon);
        hide(stopIcon);
        playStopButton.title = "Play audio";
        replaceClasses(
          playStopButton,
          ["bg-red-600", "hover:bg-red-500"],
          ["bg-blue-600", "hover:bg-blue-500"],
        );
      }

      // --- EVENT LISTENERS ---
      window.addEventListener("load", () => {
        hide(controls);
        hide(playButton);
        hideStatus();
        loadPreloadedAudio();
      });

      document.addEventListener("keydown", (e) => {
        if (e.code === "Space") {
          e.preventDefault(); // Always prevent space bar scrolling
          if (!isRecording) {
            startRecording();
          }
        } else if (e.code === "Enter" || e.code === "NumpadEnter") {
          e.preventDefault(); // Prevent form submission or other default behavior
          if (lastAudioBuffer && !isRecording) {
            togglePlayStop();
          }
        }
      });

      document.addEventListener("keyup", (e) => {
        if (e.code === "Space") {
          e.preventDefault(); // Always prevent space bar scrolling
          stopRecording();
        }
      });

      window.addEventListener("blur", () => {
        stopRecording();
      });

      window.addEventListener("resize", () => {
        if (spectrogramData.length > 0) {
          drawSpectrogram();
          drawYinPitchChart();
        }
      });

      // --- DRAG AND DROP EVENT LISTENERS ---
      dropZone.addEventListener("dragover", (e) => {
        e.preventDefault();
        e.stopPropagation();
        show(dropOverlay);
      });

      dropZone.addEventListener("dragleave", (e) => {
        e.preventDefault();
        e.stopPropagation();
        // Only hide if leaving the dropZone itself, not child elements
        if (e.target === dropZone) {
          hide(dropOverlay);
        }
      });

      dropZone.addEventListener("drop", (e) => {
        e.preventDefault();
        e.stopPropagation();
        hide(dropOverlay);

        const files = e.dataTransfer.files;
        if (files.length > 0) {
          const file = files[0];
          // Check if it's an audio file
          if (file.type.startsWith("audio/")) {
            loadDroppedAudio(file);
          } else {
            setStatus("Please drop an audio file (MP3, WAV, OGG, M4A)", {
              backgroundColor: "#d97706",
            });
          }
        }
      });

      // Generic handler for control setup and updates
      function setupControl(elementOrId, paramsObject, paramKey, config = {}) {
        const {
          eventType = "change",
          parser = (target) => target.value,
          displayElementId = null,
          formatter = (v) => v,
          onChange = null,
        } = config;

        // Support both element and elementId
        const element =
          typeof elementOrId === "string"
            ? document.getElementById(elementOrId)
            : elementOrId;

        const initialValue = paramsObject[paramKey];

        // Initialize the element with the value from params
        if (element.type === "checkbox") {
          element.checked = initialValue;
        } else {
          element.value = initialValue;
        }

        // Initialize display value if provided
        if (displayElementId) {
          setText(displayElementId, formatter(initialValue));
        }

        // Set up event listener for changes
        element.addEventListener(eventType, (e) => {
          const value = parser(e.target);
          paramsObject[paramKey] = value;

          if (displayElementId) {
            setText(displayElementId, formatter(value));
          }

          // Call optional callback
          if (onChange) {
            onChange();
          }
        });
      }

      // Helper function to redraw visualizations if data exists
      function redrawIfDataExists() {
        if (spectrogramData.length > 0) {
          drawSpectrogram();
          drawYinPitchChart();
        }
      }

      // Setup all display controls
      setupControl(colorSchemeSelect, settings, "colorScheme", {
        onChange: redrawIfDataExists,
      });

      setupControl(brightnessSlider, settings, "brightness", {
        eventType: "input",
        parser: (t) => parseInt(t.value, 10),
        displayElementId: "brightnessValue",
        onChange: redrawIfDataExists,
      });

      setupControl(contrastSlider, settings, "contrast", {
        eventType: "input",
        parser: (t) => parseFloat(t.value),
        displayElementId: "contrastValue",
        formatter: (v) => v.toFixed(1),
        onChange: redrawIfDataExists,
      });

      // --- YIN PARAMETER EVENT LISTENERS ---
      function recomputeYin() {
        if (lastAudioBuffer && yinData.length > 0) {
          showYinPitchLoadingOverlay();
          yinData = performYinAnalysis(lastAudioBuffer);
          drawYinPitchChart();
          hideYinPitchLoadingOverlay();
        }
      }

      function showYinPitchLoadingOverlay() {
        show(yinPitchLoadingOverlay);
      }

      function hideYinPitchLoadingOverlay() {
        hide(yinPitchLoadingOverlay);
      }

      // Setup all YIN parameter controls
      setupControl("yinFrameSize", yinParams, "frameSize", {
        parser: (t) => parseInt(t.value, 10),
        onChange: recomputeYin,
      });

      setupControl("yinHopSize", yinParams, "hopSize", {
        parser: (t) => parseInt(t.value, 10),
        onChange: recomputeYin,
      });

      setupControl("yinThresholdSlider", yinParams, "threshold", {
        eventType: "input",
        parser: (t) => parseFloat(t.value),
        displayElementId: "yinThresholdValue",
        formatter: (v) => v.toFixed(2),
        onChange: recomputeYin,
      });

      setupControl("yinMinFreqSlider", yinParams, "minFreq", {
        eventType: "input",
        parser: (t) => parseInt(t.value, 10),
        displayElementId: "yinMinFreqValue",
        onChange: recomputeYin,
      });

      setupControl("yinMaxFreqSlider", yinParams, "maxFreq", {
        eventType: "input",
        parser: (t) => parseInt(t.value, 10),
        displayElementId: "yinMaxFreqValue",
        onChange: recomputeYin,
      });

      setupControl("yinInterpolation", yinParams, "interpolation", {
        parser: (t) => t.checked,
        onChange: recomputeYin,
      });

      setupControl("yinFft", yinParams, "fft", {
        parser: (t) => t.checked,
        onChange: recomputeYin,
      });

      // --- CORE AUDIO FUNCTIONS ---
      async function startRecording() {
        if (isRecording) {
          return;
        }
        isRecording = true;
        audioChunks = [];

        try {
          // Ensure AudioContext is created by user gesture
          if (!audioContext) {
            audioContext = new (window.AudioContext ||
              window.webkitAudioContext)();
          }
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          if (!stream) {
            return;
          }
          if (!isRecording) {
            stream.getAudioTracks().forEach((track) => track.stop());
            return;
          }
          mediaRecorder = new MediaRecorder(stream);
          mediaRecorder.onstart = (event) => {
            setStatus("Recording...", { backgroundColor: "#ef4444" });
          };
          mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
          };
          mediaRecorder.onstop = processAudio;
          mediaRecorder.start();
        } catch (err) {
          console.error("Error accessing microphone:", err);
          setStatus(
            "Microphone access denied. Please allow access and try again.",
            { backgroundColor: "#d97706" },
          );
          isRecording = false;
        }
      }

      function stopRecording() {
        if (!isRecording) {
          return;
        }
        isRecording = false;
        if (!mediaRecorder) {
          return;
        }
        mediaRecorder.stop();

        // Clean up media stream tracks
        if (mediaRecorder.stream) {
          mediaRecorder.stream.getTracks().forEach((track) => track.stop());
        }

        setStatus("Analyzing...", { backgroundColor: "#3b82f6" });
        showYinPitchLoadingOverlay();
      }

      function processAudio() {
        const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
        const reader = new FileReader();
        reader.onload = async (e) => {
          try {
            const audioBuffer = await audioContext.decodeAudioData(
              e.target.result,
            );
            // Initialize data arrays (will be filled during spectrogram analysis)
            yinData = [];
            lastAudioBuffer = audioBuffer; // Store for replay

            // Perform YIN analysis
            yinData = performYinAnalysis(audioBuffer);

            hideYinPitchLoadingOverlay();

            analyzeAndDraw(audioBuffer);

            // Auto-play using the same functionality as the play button
            playLastRecording();
          } catch (err) {
            console.error("Error decoding audio data:", err);
            setStatus("Could not process audio. Please try again.");
          }
        };
        reader.readAsArrayBuffer(audioBlob);
      }

      function playAudio(audioBuffer) {
        // Stop any currently playing audio
        if (currentAudioSource) {
          currentAudioSource.stop();
        }

        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(audioContext.destination);

        currentAudioSource = source;
        isPlaying = true;
        updatePlayStopButton();

        // Show progress line
        showProgressLine();

        // Start progress tracking
        const duration = audioBuffer.duration;
        const startTime = Date.now();

        const progressInterval = setInterval(() => {
          if (!isPlaying) {
            clearInterval(progressInterval);
            return;
          }

          const elapsed = (Date.now() - startTime) / 1000; // Convert to seconds
          const progress = Math.min((elapsed / duration) * 100, 100);

          updateProgressLine(progress);

          if (progress >= 100 || elapsed >= duration) {
            clearInterval(progressInterval);
            isPlaying = false;
            currentAudioSource = null;
            updatePlayStopButton();
            updateProgressLine(100);
            // Keep progress line visible briefly after completion
            setTimeout(() => {
              if (!isPlaying) {
                hideProgressLine();
              }
            }, 1000);
          }
        }, PROGRESS_UPDATE_INTERVAL_MS);

        source.onended = () => {
          isPlaying = false;
          currentAudioSource = null;
          updatePlayStopButton();
          // Hide progress line when playback ends
          setTimeout(() => {
            hideProgressLine();
          }, 100);
        };

        source.start(0);
      }

      function playLastRecording() {
        if (lastAudioBuffer && audioContext) {
          playAudio(lastAudioBuffer);
        }
      }

      function stopPlayback() {
        if (currentAudioSource) {
          currentAudioSource.stop();
          currentAudioSource = null;
        }
        isPlaying = false;
        hideProgressLine();
        updatePlayStopButton();
      }

      function togglePlayStop() {
        if (isPlaying) {
          stopPlayback();
        } else {
          playLastRecording();
        }
      }

      function updatePlayStopButton() {
        if (isPlaying) {
          showPlayingState();
        } else {
          showStoppedState();
        }
      }

      async function loadPreloadedAudio() {
        try {
          // Show loading indicator
          setStatus("Processing preloaded audio...", {
            backgroundColor: "#3b82f6",
            isLoading: true,
            spinnerColor: "border-blue-300",
          });

          // Initialize audio context if not already done
          if (!audioContext) {
            audioContext = new (window.AudioContext ||
              window.webkitAudioContext)();
          }

          // Convert base64 data URL to array buffer
          const response = await fetch(PRELOADED_AUDIO_DATA);
          const arrayBuffer = await response.arrayBuffer();

          // Decode audio data
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

          // Store as last audio buffer for playback
          lastAudioBuffer = audioBuffer;

          // Initialize data arrays
          yinData = [];

          // Update loading message for YIN analysis
          setStatus("Computing YIN pitch analysis...", {
            isLoading: true,
            spinnerColor: "border-purple-300",
          });

          // Perform YIN analysis
          yinData = performYinAnalysis(audioBuffer);

          // Update loading message for spectrogram
          setStatus("Generating spectrogram...", {
            isLoading: true,
            spinnerColor: "border-green-300",
          });

          // Analyze and draw visualizations
          analyzeAndDraw(audioBuffer);

          hideStatus();

          // Show controls and play button
          showControls();

          // Auto-play the preloaded audio
          playLastRecording();
        } catch (err) {
          console.error("Error loading preloaded audio:", err);
          setStatus("Error loading preloaded audio.", {
            backgroundColor: "#d97706",
          });
        }
      }

      async function loadDroppedAudio(file) {
        try {
          // Stop any currently playing audio
          if (isPlaying) {
            stopPlayback();
          }

          // Show loading indicator
          setStatus("Processing audio file...", {
            backgroundColor: "#3b82f6",
            isLoading: true,
            spinnerColor: "border-blue-300",
          });

          // Initialize audio context if not already done
          if (!audioContext) {
            audioContext = new (window.AudioContext ||
              window.webkitAudioContext)();
          }

          // Read file as array buffer
          const arrayBuffer = await file.arrayBuffer();

          // Decode audio data
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

          // Store as last audio buffer for playback
          lastAudioBuffer = audioBuffer;

          // Initialize data arrays
          yinData = [];

          // Update loading message for YIN analysis
          setStatus("Computing YIN pitch analysis...", {
            isLoading: true,
            spinnerColor: "border-purple-300",
          });

          // Perform YIN analysis
          yinData = performYinAnalysis(audioBuffer);

          // Update loading message for spectrogram
          setStatus("Generating spectrogram...", {
            isLoading: true,
            spinnerColor: "border-green-300",
          });

          // Analyze and draw visualizations
          analyzeAndDraw(audioBuffer);

          hideStatus();

          // Show controls and play button
          showControls();

          // Auto-play the dropped audio
          playLastRecording();
        } catch (err) {
          console.error("Error loading dropped audio:", err);
          setStatus(
            "Could not process audio file. Make sure it's a valid audio format.",
            {
              backgroundColor: "#d97706",
            },
          );
        }
      }

      function analyzeAndDraw(audioBuffer) {
        const offlineCtx = new OfflineAudioContext(
          audioBuffer.numberOfChannels,
          audioBuffer.length,
          audioBuffer.sampleRate,
        );
        const source = offlineCtx.createBufferSource();
        source.buffer = audioBuffer;

        const analyser = offlineCtx.createAnalyser();
        analyser.fftSize = FFT_SIZE; // Use the new higher resolution FFT size
        analyser.smoothingTimeConstant = 0;

        // Decreased buffer size for better time (horizontal) resolution.
        const bufferSize = BUFFER_SIZE;
        const processor = offlineCtx.createScriptProcessor(bufferSize, 1, 1);

        const freqData = new Uint8Array(analyser.frequencyBinCount);
        spectrogramData = [];

        processor.onaudioprocess = (e) => {
          analyser.getByteFrequencyData(freqData);
          spectrogramData.push(new Uint8Array(freqData));
        };

        source.connect(analyser);
        analyser.connect(processor);
        processor.connect(offlineCtx.destination);

        source.start(0);

        offlineCtx
          .startRendering()
          .then(() => {
            hideStatus();
            showControls();

            drawSpectrogram();
            drawYinPitchChart();
          })
          .catch((err) => {
            console.error("Offline rendering failed:", err);
            setStatus("Error during analysis.");
          });
      }

      function drawSpectrogram() {
        const numSlices = spectrogramData.length;
        if (numSlices === 0) return;

        // --- EDITED FOR FOCUSED VIEW ---
        // Calculate how many frequency bins to show to focus on the vocal range.
        const freqPerBin = audioContext.sampleRate / FFT_SIZE;
        const relevantBins = Math.ceil(MAX_FREQ_HZ / freqPerBin);
        const totalBins = spectrogramData[0].length;
        const finalBinsToDraw = Math.min(relevantBins, totalBins);

        canvas.width = numSlices;
        canvas.height = finalBinsToDraw;

        const imageData = canvasCtx.createImageData(
          canvas.width,
          canvas.height,
        );
        const data = imageData.data;

        for (let x = 0; x < canvas.width; x++) {
          for (let y = 0; y < canvas.height; y++) {
            const value = spectrogramData[x][y];
            const color = getColor(value, settings.colorScheme);

            let r =
              settings.contrast * (color[0] - 128) + 128 + settings.brightness;
            let g =
              settings.contrast * (color[1] - 128) + 128 + settings.brightness;
            let b =
              settings.contrast * (color[2] - 128) + 128 + settings.brightness;

            r = Math.max(0, Math.min(255, r));
            g = Math.max(0, Math.min(255, g));
            b = Math.max(0, Math.min(255, b));

            const pixelIndex = ((canvas.height - 1 - y) * canvas.width + x) * 4;
            data[pixelIndex] = r;
            data[pixelIndex + 1] = g;
            data[pixelIndex + 2] = b;
            data[pixelIndex + 3] = 255;
          }
        }
        canvasCtx.putImageData(imageData, 0, 0);
      }

      function drawYinPitchChart() {
        if (yinData.length === 0) return;

        // Get display dimensions from CSS
        const displayWidth = yinPitchCanvas.clientWidth;
        const displayHeight = yinPitchCanvas.clientHeight;
        const pixelRatio = window.devicePixelRatio || 1;

        // Set high-resolution canvas dimensions
        yinPitchCanvas.width = displayWidth * pixelRatio;
        yinPitchCanvas.height = displayHeight * pixelRatio;

        // Scale context for high-DPI rendering
        yinPitchCanvasCtx.setTransform(pixelRatio, 0, 0, pixelRatio, 0, 0);

        const ctx = yinPitchCanvasCtx;
        const width = displayWidth;
        const height = displayHeight;

        // Clear canvas with transparent background
        ctx.clearRect(0, 0, width, height);

        const validPitches = yinData.filter((frame) => frame.pitch > 0);
        if (validPitches.length > 0) {
          const minPitch = Math.min(
            yinParams.minFreq,
            ...validPitches.map((f) => f.pitch),
          );
          const maxPitch = Math.max(...validPitches.map((f) => f.pitch));
          const pitchRange = Math.max(maxPitch - minPitch, 50);

          // Draw pitch line with confidence-based opacity
          ctx.lineWidth = YIN_PITCH_LINE_WIDTH;

          // Maximum vertical jump threshold
          const maxJumpThreshold = height * YIN_MAX_JUMP_THRESHOLD_PERCENT;

          let lastValidX = -1;
          let lastValidY = -1;

          for (let i = 0; i < yinData.length; i++) {
            const frame = yinData[i];
            if (frame.pitch > 0) {
              // Map time index to canvas width (matching spectrogram time axis)
              const timeRatio = i / (yinData.length - 1);
              const x = timeRatio * width;

              // Map pitch to independent Y-axis (full canvas height for pitch range)
              const pitchRatio = (frame.pitch - minPitch) / pitchRange;
              const y = height - pitchRatio * height;

              // Color based on confidence with bright, visible colors
              const alpha = Math.max(0.1, frame.confidence);
              const strokeAlpha = 0.5;

              // Use bright yellow/white for high visibility over spectrogram
              ctx.strokeStyle = `rgba(255, 255, 0, ${strokeAlpha})`;
              ctx.fillStyle = `rgba(255, 255, 255, ${alpha})`;

              // Draw line connecting consecutive valid pitch points only if jump is small enough
              if (lastValidX >= 0 && lastValidY >= 0) {
                const verticalJump = Math.abs(y - lastValidY);

                // Only draw connecting line if the jump is below threshold
                if (verticalJump < maxJumpThreshold) {
                  ctx.beginPath();
                  ctx.moveTo(lastValidX, lastValidY);
                  ctx.lineTo(x, y);
                  ctx.stroke();
                }
              }

              ctx.beginPath();
              ctx.arc(x, y, YIN_PITCH_POINT_RADIUS, 0, 2 * Math.PI);
              ctx.fill();

              // Reset shadow for next elements
              ctx.shadowColor = "transparent";
              ctx.shadowBlur = 0;
              ctx.shadowOffsetX = 0;
              ctx.shadowOffsetY = 0;

              lastValidX = x;
              lastValidY = y;
            } else {
              // Reset line drawing when pitch is invalid
              lastValidX = -1;
              lastValidY = -1;
            }
          }

          // Draw pitch range labels on the overlay
          ctx.fillStyle = "rgba(255, 255, 255, 0.9)";
          ctx.font = "12px Inter";
          ctx.textAlign = "left";
          ctx.fillText(`${Math.round(maxPitch)}Hz`, 5, 20);
          ctx.fillText(`${Math.round(minPitch)}Hz`, 5, height - 10);
        } else {
          ctx.fillStyle = "#9CA3AF";
          ctx.font = "14px Inter";
          ctx.textAlign = "center";
          ctx.fillText("No pitch detected", width / 2, height / 2);
        }
      }
    </script>
    <script src="fftjs.min.js"></script>
  </body>
</html>
