<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
      Pitch (Tone) Analyzer for Mandarin Practice - emira.ga (Emir Bosnian)
    </title>
    <link href="./output.css" rel="stylesheet" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
      }
      /* Style for the canvas to make it responsive and sharp */
      canvas {
        width: 100%;
        height: 300px;
        background-color: #111827; /* bg-gray-900 */
        border-radius: 0.5rem;
        image-rendering: -moz-crisp-edges;
        image-rendering: -webkit-crisp-edges;
        image-rendering: pixelated;
        image-rendering: crisp-edges;
      }
      /* Custom styles for range sliders */
      input[type="range"] {
        -webkit-appearance: none;
        appearance: none;
        width: 100%;
        height: 8px;
        background: #4b5563; /* bg-gray-600 */
        border-radius: 5px;
        outline: none;
        opacity: 0.7;
        transition: opacity 0.2s;
      }
      input[type="range"]:hover {
        opacity: 1;
      }
      input[type="range"]::-webkit-slider-thumb {
        -webkit-appearance: none;
        appearance: none;
        width: 20px;
        height: 20px;
        background: #3b82f6; /* bg-blue-500 */
        cursor: pointer;
        border-radius: 50%;
      }
      input[type="range"]::-moz-range-thumb {
        width: 20px;
        height: 20px;
        background: #3b82f6; /* bg-blue-500 */
        cursor: pointer;
        border-radius: 50%;
      }
    </style>
  </head>
  <body
    class="bg-gray-800 text-gray-200 flex-col items-center justify-center min-h-screen p-4"
  >
    <!-- Full-page drag and drop overlay -->
    <div
      id="dropOverlay"
      class="fixed inset-0 bg-blue-800/80 border-4 border-dashed border-blue-400 flex items-center justify-center hidden"
      style="z-index: 9999"
    >
      <div class="text-center">
        <svg
          class="w-16 h-16 mx-auto mb-4 text-blue-300"
          fill="none"
          stroke="currentColor"
          viewBox="0 0 24 24"
        >
          <path
            stroke-linecap="round"
            stroke-linejoin="round"
            stroke-width="2"
            d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12"
          ></path>
        </svg>
        <p class="text-blue-100 text-xl font-medium">Drop audio file here</p>
        <p class="text-blue-200 text-sm mt-2">
          Supported formats: MP3, WAV, OGG, M4A
        </p>
      </div>
    </div>

    <div class="w-full max-w-4xl mx-auto">
      <!-- Spectrogram Canvas with YIN Pitch Overlay -->
      <div
        id="dropZone"
        class="w-full bg-gray-900 rounded-lg shadow-lg p-2 relative transition-all duration-200"
      >
        <div class="relative">
          <canvas id="spectrogramCanvas"></canvas>
          <canvas
            id="yinPitchCanvas"
            class="absolute top-0 left-0 pointer-events-none"
            style="background: transparent"
          ></canvas>
          <div
            id="progressLine"
            class="absolute top-0 w-0.5 bg-white opacity-90 pointer-events-none hidden"
            style="height: 100%; left: 0%; transition: left 0.1s linear"
          ></div>
        </div>
        <div
          id="yinPitchLoadingOverlay"
          class="absolute inset-0 bg-gray-900/80 flex items-center justify-center rounded-lg hidden"
        >
          <div class="text-center">
            <div
              class="animate-spin rounded-full h-8 w-8 border-b-2 border-purple-500 mx-auto mb-2"
            ></div>
            <p class="text-gray-300 text-sm">Computing YIN pitch...</p>
          </div>
        </div>
        <!-- Play Button -->
        <div id="playButton" class="flex justify-center mt-3">
          <button
            id="playStopButton"
            onclick="togglePlayStop()"
            class="flex items-center justify-center w-12 h-12 bg-blue-600 hover:bg-blue-500 rounded-full transition-colors duration-200 shadow-lg"
            title="Play audio"
          >
            <svg
              id="playIcon"
              class="w-6 h-6 text-white ml-0.5"
              fill="currentColor"
              viewBox="0 0 24 24"
            >
              <path d="M8 5v14l11-7z" />
            </svg>
            <svg
              id="stopIcon"
              class="w-6 h-6 text-white hidden"
              fill="currentColor"
              viewBox="0 0 24 24"
            >
              <rect x="6" y="6" width="12" height="12" />
            </svg>
          </button>
          <div class="p-3.5">
            or press
            <kbd
              class="px-2 py-1.5 text-xs font-semibold text-gray-800 bg-gray-100 border border-gray-200 rounded-lg"
              >Enter</kbd
            >
            to play, hold
            <kbd
              class="px-2 py-1.5 text-xs font-semibold text-gray-800 bg-gray-100 border border-gray-200 rounded-lg"
              >Space</kbd
            >
            to record, or drag & drop an audio file.
          </div>
        </div>
      </div>

      <!-- Status Message -->
      <div
        id="status"
        class="text-center mb-4 p-3 rounded-lg bg-gray-700 transition-all duration-300"
      >
        <div class="flex items-center justify-center">
          <div
            id="statusSpinner"
            class="animate-spin rounded-full h-4 w-4 border-b-2 border-blue-300 mr-2 hidden"
          ></div>
          <p id="instructions" class="text-lg font-medium text-blue-300">
            Loading...
          </p>
        </div>
      </div>

      <!-- Algorithm Controls -->
      <div
        id="yinControlsSection"
        class="mt-3 hidden py-3 border-t border-gray-600"
      >
        <!-- YIN Controls -->
        <div>
          <button
            id="yinControlsToggle"
            class="flex items-center gap-2 text-sm font-medium transition-colors cursor-pointer"
            onclick="toggleYinControls()"
            title="Click to expand/collapse"
          >
            <span>YIN Algorithm parameters:</span>
            <svg
              id="yinControlsChevron"
              class="w-5 h-5 transform transition-transform duration-200"
              fill="none"
              stroke="currentColor"
              viewBox="0 0 24 24"
            >
              <path
                stroke-linecap="round"
                stroke-linejoin="round"
                stroke-width="2"
                d="M19 9l-7 7-7-7"
              />
            </svg>
          </button>

          <div
            id="yinControls"
            class="hidden grid-cols-2 md:grid-cols-3 gap-4 bg-gray-700/50 p-4 rounded-lg mt-3"
          >
            <!---->
            <div>
              <label
                for="yinDifferenceMethod"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Difference Function</label
              >
              <select
                id="yinDifferenceMethod"
                class="bg-gray-600 border border-gray-500 text-white text-xs rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-1"
              >
                <option value="simple">Simple (Slow)</option>
                <option value="fftSimple">FFT Simple</option>
                <option value="fftZeroPadding">FFT Zero-Padding</option>
              </select>
            </div>

            <div>
              <label
                for="yinFrameSize"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Frame Size</label
              >
              <select
                id="yinFrameSize"
                class="bg-gray-600 border border-gray-500 text-white text-xs rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-1"
              >
                <option value="128">128</option>
                <option value="256">256</option>
                <option value="512">512</option>
                <option value="1024">1024</option>
                <option value="2048">2048</option>
                <option value="4096">4096</option>
              </select>
            </div>

            <div>
              <label
                for="yinHopSize"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Hop Size</label
              >
              <select
                id="yinHopSize"
                class="bg-gray-600 border border-gray-500 text-white text-xs rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-1"
              >
                <option value="16">16</option>
                <option value="32">32</option>
                <option value="64">64</option>
                <option value="128">128</option>
                <option value="256">256</option>
                <option value="512">512</option>
                <option value="1024">1024</option>
                <option value="2048">2048</option>
                <option value="4096">4096</option>
              </select>
            </div>

            <div>
              <label
                for="yinThreshold"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Threshold</label
              >
              <input
                type="range"
                id="yinThresholdSlider"
                min="0.05"
                max="0.9"
                step="0.01"
                class="w-full"
              />
              <div
                class="text-xs text-gray-400 text-center mt-1"
                id="yinThresholdValue"
              ></div>
            </div>

            <div>
              <label
                for="yinFallbackThreshold"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Fallback Threshold</label
              >
              <input
                type="range"
                id="yinFallbackThresholdSlider"
                min="0.1"
                max="1.0"
                step="0.05"
                class="w-full"
              />
              <div
                class="text-xs text-gray-400 text-center mt-1"
                id="yinFallbackThresholdValue"
              ></div>
            </div>

            <div>
              <label
                for="yinThresholdMethod"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Threshold Method</label
              >
              <select
                id="yinThresholdMethod"
                class="bg-gray-600 border border-gray-500 text-white text-xs rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-1"
              >
                <option value="simple">Simple</option>
                <option value="adaptive">Adaptive</option>
              </select>
            </div>

            <div>
              <label
                for="yinMinFreq"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Min Freq (Hz)</label
              >
              <input
                type="range"
                id="yinMinFreqSlider"
                min="10"
                max="200"
                step="5"
                class="w-full"
              />
              <div
                class="text-xs text-gray-400 text-center mt-1"
                id="yinMinFreqValue"
              ></div>
            </div>

            <div>
              <label
                for="yinMaxFreq"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Max Freq (Hz)</label
              >
              <input
                type="range"
                id="yinMaxFreqSlider"
                min="100"
                max="1000"
                step="10"
                class="w-full"
              />
              <div
                class="text-xs text-gray-400 text-center mt-1"
                id="yinMaxFreqValue"
              ></div>
            </div>

            <div class="flex items-center">
              <input
                type="checkbox"
                id="yinInterpolation"
                class="w-4 h-4 text-blue-600 bg-gray-700 border-gray-600 rounded focus:ring-blue-500"
              />
              <label
                for="yinInterpolation"
                class="ml-2 text-xs font-medium text-gray-300"
                >Parabolic Interpolation</label
              >
            </div>

            <div class="flex items-center">
              <input
                type="checkbox"
                id="yinPowerConfidenceAdjust"
                class="w-4 h-4 text-blue-600 bg-gray-700 border-gray-600 rounded focus:ring-blue-500"
              />
              <label
                for="yinPowerConfidenceAdjust"
                class="ml-2 text-xs font-medium text-gray-300"
                >Power based confidence adjust</label
              >
            </div>

            <div>
              <label
                for="yinMinPowerThreshold"
                class="block mb-2 text-xs font-medium text-gray-300"
                >Min Power Threshold</label
              >
              <input
                type="range"
                id="yinMinPowerThresholdSlider"
                min="0.001"
                max="0.1"
                step="0.001"
                class="w-full"
              />
              <div
                class="text-xs text-gray-400 text-center mt-1"
                id="yinMinPowerThresholdValue"
              ></div>
            </div>

            <!---->
          </div>
        </div>
      </div>

      <!-- Display Controls -->
      <div id="controls" class="py-3 border-t border-b border-gray-600">
        <button
          id="displayControlsToggle"
          class="flex items-center gap-2 text-gray-300 text-sm font-medium hover:text-gray-100 transition-colors cursor-pointer"
          onclick="toggleDisplayControls()"
          title="Click to expand/collapse"
        >
          <span>Display Settings:</span>
          <svg
            id="displayControlsChevron"
            class="w-5 h-5 transform transition-transform duration-200"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="2"
              d="M19 9l-7 7-7-7"
            />
          </svg>
        </button>

        <div
          id="displayControlsContent"
          class="hidden grid-cols-2 md:grid-cols-3 mt-3 gap-6 bg-gray-700/50 p-6 rounded-lg"
        >
          <div>
            <label
              for="brightness"
              class="block mb-2 text-sm font-medium text-gray-300"
              >Brightness</label
            >
            <input
              type="range"
              id="brightness"
              min="-150"
              max="100"
              class="w-full"
            />
            <div
              class="text-xs text-gray-400 text-center mt-1"
              id="brightnessValue"
            ></div>
          </div>
          <div>
            <label
              for="contrast"
              class="block mb-2 text-sm font-medium text-gray-300"
              >Contrast</label
            >
            <input
              type="range"
              id="contrast"
              min="0.0"
              max="5.0"
              step="0.1"
              class="w-full"
            />
            <div
              class="text-xs text-gray-400 text-center mt-1"
              id="contrastValue"
            ></div>
          </div>
          <div>
            <label
              for="colorScheme"
              class="block mb-2 text-sm font-medium text-gray-300"
              >Color Scheme</label
            >
            <select
              id="colorScheme"
              class="bg-gray-600 border border-gray-500 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-1"
            >
              <option value="viridis">Viridis</option>
              <option value="plasma">Plasma</option>
              <option value="hot">Hot</option>
              <option value="grayscale">Grayscale</option>
            </select>
          </div>
        </div>
      </div>

      <!-- Recording Controls -->
      <div id="recordingControls" class="py-3 border-b border-gray-600">
        <button
          id="recordingControlsToggle"
          class="flex items-center gap-2 text-gray-300 text-sm font-medium hover:text-gray-100 transition-colors cursor-pointer"
          onclick="toggleRecordingControls()"
          title="Click to expand/collapse"
        >
          <span>Recording Settings:</span>
          <svg
            id="recordingControlsChevron"
            class="w-5 h-5 transform transition-transform duration-200"
            fill="none"
            stroke="currentColor"
            viewBox="0 0 24 24"
          >
            <path
              stroke-linecap="round"
              stroke-linejoin="round"
              stroke-width="2"
              d="M19 9l-7 7-7-7"
            />
          </svg>
        </button>

        <div
          id="recordingControlsContent"
          class="hidden grid-cols-2 md:grid-cols-3 mt-3 gap-6 bg-gray-700/50 p-6 rounded-lg"
        >
          <div>
            <label
              for="recordingSampleRate"
              class="block mb-2 text-sm font-medium text-gray-300"
              >Sample Rate (Hz)</label
            >
            <select
              id="recordingSampleRate"
              class="bg-gray-600 border border-gray-500 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-1"
            >
              <option value="8000">8000</option>
              <option value="16000">16000</option>
              <option value="22050">22050</option>
              <option value="44100">44100</option>
              <option value="48000">48000</option>
              <option value="96000">96000</option>
            </select>
          </div>
          <div>
            <label
              for="recordingChannelCount"
              class="block mb-2 text-sm font-medium text-gray-300"
              >Channel Count</label
            >
            <select
              id="recordingChannelCount"
              class="bg-gray-600 border border-gray-500 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-1"
            >
              <option value="1">Mono (1)</option>
              <option value="2">Stereo (2)</option>
            </select>
          </div>
          <div class="flex items-center">
            <input
              type="checkbox"
              id="recordingEchoCancellation"
              class="w-4 h-4 text-blue-600 bg-gray-700 border-gray-600 rounded focus:ring-blue-500"
            />
            <label
              for="recordingEchoCancellation"
              class="ml-2 text-sm font-medium text-gray-300"
              >Echo Cancellation</label
            >
          </div>
          <div class="flex items-center">
            <input
              type="checkbox"
              id="recordingNoiseSuppression"
              class="w-4 h-4 text-blue-600 bg-gray-700 border-gray-600 rounded focus:ring-blue-500"
            />
            <label
              for="recordingNoiseSuppression"
              class="ml-2 text-sm font-medium text-gray-300"
              >Noise Suppression</label
            >
          </div>
          <div class="flex items-center">
            <input
              type="checkbox"
              id="recordingAutoGainControl"
              class="w-4 h-4 text-blue-600 bg-gray-700 border-gray-600 rounded focus:ring-blue-500"
            />
            <label
              for="recordingAutoGainControl"
              class="ml-2 text-sm font-medium text-gray-300"
              >Auto Gain Control</label
            >
          </div>
        </div>
      </div>
      <!---->
    </div>

    <!-- Audio File Links -->
    <div class="w-full max-w-4xl mx-auto mt-3">
      <div class="bg-gray-700/50 p-4 rounded-lg">
        <h4 class="text-gray-300 text-sm font-medium mb-3">
          Load Sample Audio Files: (you can also drag-and-drop your own audio
          files)
        </h4>
        <div class="flex flex-col gap-3">
          <div class="flex items-center gap-3">
            <button
              onclick="loadAudioFile('audio/ai_讀書寫字.mp3', 300)"
              class="cursor-pointer px-4 py-2 bg-gray-600 hover:bg-gray-500 text-white text-sm rounded-lg transition-colors duration-200 whitespace-nowrap"
            >
              ai_讀書寫字.mp3
            </button>
            <span class="text-gray-400 text-sm">
              AI voice: "dú shū xiě zì" (read books, write characters)
            </span>
          </div>

          <div class="flex items-center gap-3">
            <button
              onclick="loadAudioFile('audio/ai_高富帥_gao1_fu4_shuai4.mp3', 400)"
              class="cursor-pointer px-4 py-2 bg-gray-600 hover:bg-gray-500 text-white text-sm rounded-lg transition-colors duration-200 whitespace-nowrap"
            >
              ai_高富帥_gao1_fu4_shuai4.mp3
            </button>
            <span class="text-gray-400 text-sm">
              AI voice: "gāo fù shuài" (tall, rich, handsome)
            </span>
          </div>

          <div class="flex items-center gap-3">
            <button
              onclick="loadAudioFile('audio/ai_今天不用上班.mp3', 400)"
              class="cursor-pointer px-4 py-2 bg-gray-600 hover:bg-gray-500 text-white text-sm rounded-lg transition-colors duration-200 whitespace-nowrap"
            >
              ai_今天不用上班.mp3
            </button>
            <span class="text-gray-400 text-sm">
              AI voice: "jīn tiān bù yòng shàng bān" (don't have to work today)
            </span>
          </div>

          <div class="flex items-center gap-3">
            <button
              onclick="loadAudioFile('audio/human_我喜歡吃東西.m4a', 400)"
              class="cursor-pointer px-4 py-2 bg-gray-600 hover:bg-gray-500 text-white text-sm rounded-lg transition-colors duration-200 whitespace-nowrap"
            >
              human_我喜歡吃東西.m4a
            </button>
            <span class="text-gray-400 text-sm">
              Human voice: "wǒ xǐ huān chī dōng xī" (I like to eat things)
            </span>
          </div>

          <div class="flex items-center gap-3">
            <button
              onclick="loadAudioFile('audio/human_我一歲了.m4a', 400)"
              class="cursor-pointer px-4 py-2 bg-gray-600 hover:bg-gray-500 text-white text-sm rounded-lg transition-colors duration-200 whitespace-nowrap"
            >
              human_我一歲了.m4a
            </button>
            <span class="text-gray-400 text-sm">
              Human voice: "wǒ yī suì le" (I am one year old)
            </span>
          </div>

          <div class="flex items-center gap-3">
            <button
              onclick="loadAudioFile('audio/367215_1847127-lq.mp3', 400)"
              class="cursor-pointer px-4 py-2 bg-gray-600 hover:bg-gray-500 text-white text-sm rounded-lg transition-colors duration-200 whitespace-nowrap"
            >
              367215_1847127-lq.mp3
            </button>
            <span class="text-gray-400 text-sm"
              >Music: Male voice La la la la la la</span
            >
          </div>

          <div class="flex items-center gap-3">
            <button
              onclick="loadAudioFile('audio/427200_8176931-lq.mp3', 500)"
              class="cursor-pointer px-4 py-2 bg-gray-600 hover:bg-gray-500 text-white text-sm rounded-lg transition-colors duration-200 whitespace-nowrap"
            >
              427200_8176931-lq.mp3
            </button>
            <span class="text-gray-400 text-sm">
              Music: Beatiful female melody. Warning! Increase Max Freq to
              500Hz, also warning! since voice is soft, you may need to reduce
              "Min Power Threshold"
            </span>
          </div>

          <div class="flex items-center gap-3">
            <button
              onclick="loadAudioFile('audio/417938_8176931-lq.mp3', 500)"
              class="cursor-pointer px-4 py-2 bg-gray-600 hover:bg-gray-500 text-white text-sm rounded-lg transition-colors duration-200 whitespace-nowrap"
            >
              417938_8176931-lq.mp3
            </button>
            <span class="text-gray-400 text-sm">
              Music: Female singing "Do you want to be beautiful?" Warning!
              Increase Max Freq to 500Hz
            </span>
          </div>

          <div class="flex items-center gap-3">
            <button
              onclick="loadAudioFile('audio/30084_129090-lq.mp3', 800)"
              class="cursor-pointer px-4 py-2 bg-gray-600 hover:bg-gray-500 text-white text-sm rounded-lg transition-colors duration-200 whitespace-nowrap"
            >
              30084_129090-lq.mp3
            </button>
            <span class="text-gray-400 text-sm">
              Music: Very high female tone, Warning! Increase Max Freq to 800Hz
            </span>
          </div>
        </div>
      </div>
    </div>

    <!---->
    <script>
      // DOM Elements
      const instructions = document.getElementById("instructions");
      const statusDiv = document.getElementById("status");
      const statusSpinner = document.getElementById("statusSpinner");
      const canvas = document.getElementById("spectrogramCanvas");
      const canvasCtx = canvas.getContext("2d");
      const progressLine = document.getElementById("progressLine");
      const yinPitchCanvas = document.getElementById("yinPitchCanvas");
      const yinPitchCanvasCtx = yinPitchCanvas.getContext("2d");
      const controls = document.getElementById("controls");
      const playButton = document.getElementById("playButton");
      const playStopButton = document.getElementById("playStopButton");
      const playIcon = document.getElementById("playIcon");
      const stopIcon = document.getElementById("stopIcon");
      const colorSchemeSelect = document.getElementById("colorScheme");
      const brightnessSlider = document.getElementById("brightness");
      const contrastSlider = document.getElementById("contrast");
      const yinPitchLoadingOverlay = document.getElementById(
        "yinPitchLoadingOverlay",
      );
      const yinControlsSection = document.getElementById("yinControlsSection");
      const dropZone = document.getElementById("dropZone");
      const dropOverlay = document.getElementById("dropOverlay");

      // Audio & State Variables
      let audioContext;
      let mediaRecorder;
      let isRecording = false;
      let audioChunks = [];
      let spectrogramData = [];
      let yinData = [];
      let lastAudioBuffer = null;
      let currentAudioSource = null;
      let isPlaying = false;
      let progressAnimationFrame = null;
      let audioStartTime = null;
      let audioDuration = null;

      // Audio recording sample rate (48000 Hz is high quality, standard for pro audio)
      const RECORDING_SAMPLE_RATE = 48000;

      // Visualization Settings
      let settings = {
        colorScheme: "viridis",
        brightness: -75,
        contrast: 1.5,
      };

      // Recording Settings
      let recordingSettings = {
        sampleRate: 48000,
        channelCount: 1,
        echoCancellation: false,
        noiseSuppression: false,
        autoGainControl: false,
      };

      // YIN Algorithm Parameters
      let yinParams = {
        frameSize: 2048, // Window size for analysis
        hopSize: 256, // Step size between frames
        threshold: 0.3, // Absolute threshold for period detection
        fallbackThreshold: 0.8, // Fallback threshold for adaptive method
        minFreq: 30, // Minimum frequency to consider (Hz)
        maxFreq: 400, // Maximum frequency to consider (Hz)
        interpolation: true, // Enable parabolic interpolation
        differenceMethod: "fftZeroPadding", // Difference function method: "simple", "fftSimple", or "fftZeroPadding"
        thresholdMethod: "adaptive", // Threshold method: "simple", "adaptive"
        powerConfidenceAdjust: true,
        minPowerThreshold: 0.02, // Power threshold below which confidence is reduced
      };

      // --- ANALYSIS CONSTANTS (EDITED FOR HIGHER RESOLUTION) ---
      // Increased FFT_SIZE for better frequency (vertical) resolution.
      const FFT_SIZE = 4096 * 2;
      // The maximum frequency (in Hz) to display. This focuses the view on the vocal range.
      const MAX_FREQ_HZ = 1300;
      // is about how often we do the analysis. The system collects audio into a buffer, and every time the buffer is full, it runs the analysis.
      const BUFFER_SIZE = 256;

      // --- UI CONSTANTS ---
      // Maximum vertical jump threshold as percentage of canvas height for YIN pitch chart
      const YIN_MAX_JUMP_THRESHOLD_PERCENT = 0.1;
      // Pitch point radius in pixels for YIN pitch visualization
      const YIN_PITCH_POINT_RADIUS = 3;
      // Line width for YIN pitch chart
      const YIN_PITCH_LINE_WIDTH = 3;

      // --- COLOR MAPS ---
      const COLOR_MAPS = {
        viridis: [
          [68, 1, 84],
          [72, 40, 120],
          [62, 74, 137],
          [49, 104, 142],
          [38, 130, 142],
          [31, 158, 137],
          [53, 183, 121],
          [109, 205, 89],
          [180, 222, 44],
          [253, 231, 37],
        ],
        plasma: [
          [13, 8, 135],
          [72, 1, 163],
          [120, 1, 168],
          [163, 29, 151],
          [201, 62, 122],
          [230, 99, 90],
          [249, 139, 64],
          [254, 183, 43],
          [240, 226, 33],
        ],
        hot: [
          [0, 0, 0],
          [255, 0, 0],
          [255, 255, 0],
          [255, 255, 255],
        ],
        grayscale: [
          [0, 0, 0],
          [255, 255, 255],
        ],
      };

      function interpolateColor(c1, c2, factor) {
        const result = c1.slice();
        for (let i = 0; i < 3; i++) {
          result[i] = Math.round(result[i] + factor * (c2[i] - result[i]));
        }
        return result;
      }

      function getColor(value, schemeName) {
        const map = COLOR_MAPS[schemeName];
        const scaledValue = (value / 255) * (map.length - 1);
        const colorIndex = Math.floor(scaledValue);
        const factor = scaledValue - colorIndex;

        if (colorIndex >= map.length - 1) {
          return map[map.length - 1];
        }
        return interpolateColor(map[colorIndex], map[colorIndex + 1], factor);
      }

      // --- YIN ALGORITHM IMPLEMENTATION ---

      /**
       * Calculate RMS (Root Mean Square) power of an audio frame
       * This gives us a measure of the signal strength/loudness
       * @param frame Audio frame buffer
       * @returns RMS power value (0 to 1 range typically)
       */
      function calculateRMSPower(frame) {
        let sumSquares = 0;
        for (let i = 0; i < frame.length; i++) {
          sumSquares += frame[i] * frame[i];
        }
        return Math.sqrt(sumSquares / frame.length);
      }

      /**
       * Adjust confidence based on audio power
       * Low power signals are less reliable for pitch detection
       * @param confidence Original confidence value (0-1)
       * @param power RMS power of the frame
       * @returns Adjusted confidence value
       */
      function adjustConfidenceByPower(confidence, power) {
        if (power < yinParams.minPowerThreshold) {
          return 0;
        }
        return confidence;
      }

      function yinDifferenceFunction(buffer) {
        const bufferSize = buffer.length;
        const differenceFunction = new Array(bufferSize / 2);

        // Step 1: Difference function d_t(τ) = Σ(x_j - x_{j+τ})²
        for (let tau = 0; tau < bufferSize / 2; tau++) {
          let sum = 0;
          for (let j = 0; j < bufferSize / 2; j++) {
            const delta = buffer[j] - buffer[j + tau];
            sum += delta * delta;
          }
          differenceFunction[tau] = sum;
        }

        return differenceFunction;
      }

      /**
       * Calculates the YIN difference function using an FFT-based approach
       * for improved performance.
       * @param buffer The audio frame buffer.
       * @returns The difference function array.
       */
      function yinDifferenceFunctionFFTSimple(buffer) {
        const bufferSize = buffer.length;
        const halfBufferSize = bufferSize / 2;
        const differenceFunction = new Array(halfBufferSize).fill(0);

        // 1. Pad buffer to next power of 2 for FFT
        const fftSize = 1 << Math.ceil(Math.log2(bufferSize));
        const fft = new FFTJS(fftSize);

        const paddedBuffer = new Float32Array(fftSize);
        paddedBuffer.set(buffer);

        // 2. Compute FFT
        const fftResult = fft.createComplexArray();
        fft.realTransform(fftResult, paddedBuffer);

        // 3. Calculate Power Spectral Density (PSD)
        const psd = new Float32Array(fftSize);
        for (let i = 0; i < fftSize; i += 2) {
          const real = fftResult[i];
          const imag = fftResult[i + 1];
          psd[i / 2] = real * real + imag * imag;
        }

        // 4. Compute IFFT of PSD to get autocorrelation
        const autocorrelationComplex = fft.createComplexArray();
        // We need to transform the real-valued PSD into a complex format for IFFT
        for (let i = 0; i < psd.length; i++) {
          autocorrelationComplex[i * 2] = psd[i];
          autocorrelationComplex[i * 2 + 1] = 0;
        }
        const autocorrelationResult = fft.createComplexArray();
        fft.inverseTransform(autocorrelationResult, autocorrelationComplex);

        // 5. Calculate the difference function from autocorrelation
        // d(τ) ≈ 2 * (r(0) - r(τ))
        // We only need the real part of the autocorrelation
        const r0 = autocorrelationResult[0];
        for (let tau = 1; tau < halfBufferSize; tau++) {
          differenceFunction[tau] = r0 - autocorrelationResult[tau * 2];
        }

        // The difference function at tau=0 is 0
        differenceFunction[0] = 0;

        return differenceFunction;
      }

      /**
       * Calculates the YIN difference function using a corrected FFT-based approach
       * with sufficient zero-padding for linear correlation.
       */
      function yinDifferenceFunctionFftZeroPadding(buffer) {
        const N = buffer.length; // Original buffer size
        const halfBufferSize = N / 2;
        const differenceFunction = new Array(halfBufferSize).fill(0); // 1. Correct Zero-Padding: Pad to next power of 2 >= 2*N - 1

        const requiredSize = 2 * N - 1;
        const fftSize = 1 << Math.ceil(Math.log2(requiredSize)); // M: Smallest power of 2 >= 2*N - 1
        // Initialize the FFT library with the new, larger size
        const fft = new FFTJS(fftSize); // Create a padded buffer (padded with zeros)

        const paddedBuffer = new Float32Array(fftSize);
        paddedBuffer.set(buffer); // 2. Compute FFT

        const fftResult = fft.createComplexArray();
        fft.realTransform(fftResult, paddedBuffer); // 3. Calculate Power Spectral Density (PSD)

        const psd = new Float32Array(fftSize / 2); // PSD is symmetric, only need first half
        for (let i = 0; i < fftSize; i += 2) {
          const real = fftResult[i];
          const imag = fftResult[i + 1];
          psd[i / 2] = real * real + imag * imag;
        } // 4. Compute IFFT of PSD to get autocorrelation

        const autocorrelationComplex = fft.createComplexArray(); // Transform the real-valued PSD into a complex format for IFFT
        for (let i = 0; i < psd.length; i++) {
          autocorrelationComplex[i * 2] = psd[i];
          autocorrelationComplex[i * 2 + 1] = 0;
        }
        const autocorrelationResult = fft.createComplexArray();
        fft.inverseTransform(autocorrelationResult, autocorrelationComplex); // 5. Calculate the difference function from autocorrelation
        // The IFFT results are scaled by 1/fftSize. This should be accounted for.

        const scaleFactor = 1.0 / fftSize; // r(0) is the first (real) element, scaled
        const r0 = autocorrelationResult[0] * scaleFactor;
        differenceFunction[0] = 0; // d(0) is 0

        for (let tau = 1; tau < halfBufferSize; tau++) {
          // r(tau) is the real part of the tau-th element, scaled
          const r_tau = autocorrelationResult[tau * 2] * scaleFactor; // Use the approximation d(τ) ≈ 2 * (r(0) - r(τ))
          differenceFunction[tau] = 2.0 * (r0 - r_tau);
        }

        return differenceFunction;
      }

      function yinCumulativeMeanNormalizedDifference(differenceFunction) {
        const cmndf = new Array(differenceFunction.length);
        cmndf[0] = 1;

        // Step 2: Cumulative mean normalized difference function
        // d'_t(τ) = { 1 if τ = 0
        //           { d_t(τ) / ((1/τ) * Σ_{j=1}^τ d_t(j)) if τ ≠ 0
        let runningSum = 0;
        for (let tau = 1; tau < differenceFunction.length; tau++) {
          runningSum += differenceFunction[tau];
          cmndf[tau] = differenceFunction[tau] / (runningSum / tau);
        }

        return cmndf;
      }

      function yinAbsoluteThresholdSimple(cmndf, threshold, sampleRate) {
        // Step 3: Absolute threshold
        // Find the first minimum below the threshold
        for (let tau = 2; tau < cmndf.length; tau++) {
          if (cmndf[tau] < threshold) {
            // Check if this is a local minimum
            while (tau + 1 < cmndf.length && cmndf[tau + 1] < cmndf[tau]) {
              tau++;
            }
            return tau;
          }
        }
        return -1; // No period found
      }

      /**
       * Adaptive threshold approach: Finds the best pitch candidate using multiple strategies
       * 1. Look for deepest minimum below threshold (original behavior)
       * 2. If no candidate found, find global minimum within valid frequency range
       * 3. Use a dynamic threshold based on signal characteristics
       */
      function yinAbsoluteThresholdAdaptive(cmndf, threshold, sampleRate) {
        const minTau = Math.floor(sampleRate / yinParams.maxFreq);
        const maxTau = Math.floor(sampleRate / yinParams.minFreq);

        // Clamp search range to valid indices
        const startTau = Math.max(2, minTau);
        const endTau = Math.min(cmndf.length - 1, maxTau);

        // Strategy 1: Find deepest minimum below threshold within frequency range
        let bestTau = -1;
        let bestValue = threshold;

        for (let tau = startTau; tau < endTau; tau++) {
          if (cmndf[tau] < bestValue) {
            // Check if this is a local minimum
            const isLocalMin =
              (tau === startTau || cmndf[tau] <= cmndf[tau - 1]) &&
              (tau === endTau - 1 || cmndf[tau] <= cmndf[tau + 1]);

            if (isLocalMin) {
              bestValue = cmndf[tau];
              bestTau = tau;
            }
          }
        }

        // Strategy 2: If no candidate below threshold, find global minimum
        // but only accept if it's reasonably good (< 0.5 which indicates some periodicity)
        if (bestTau === -1) {
          let globalMinTau = -1;
          let globalMinValue = 1.0;

          for (let tau = startTau; tau < endTau; tau++) {
            // Check if this is a local minimum
            const isLocalMin =
              (tau === startTau || cmndf[tau] <= cmndf[tau - 1]) &&
              (tau === endTau - 1 || cmndf[tau] <= cmndf[tau + 1]);

            if (isLocalMin && cmndf[tau] < globalMinValue) {
              globalMinValue = cmndf[tau];
              globalMinTau = tau;
            }
          }

          // Only accept global minimum if it shows reasonable periodicity
          if (globalMinValue < yinParams.fallbackThreshold) {
            bestTau = globalMinTau;
          }
        }

        return bestTau;
      }

      function yinParabolicInterpolation(cmndf, tauEstimate) {
        // Step 4: Parabolic interpolation for better accuracy
        if (tauEstimate < 1 || tauEstimate >= cmndf.length - 1) {
          return tauEstimate;
        }

        const s0 = cmndf[tauEstimate - 1];
        const s1 = cmndf[tauEstimate];
        const s2 = cmndf[tauEstimate + 1];

        // Parabolic interpolation formula
        const betterTau = tauEstimate + (s2 - s0) / (2 * (2 * s1 - s2 - s0));
        return betterTau;
      }

      // Mapping of threshold method names to functions
      const yinThresholdMethods = {
        simple: yinAbsoluteThresholdSimple,
        adaptive: yinAbsoluteThresholdAdaptive,
      };

      // Mapping of difference function method names to functions
      const yinDifferenceMethods = {
        simple: yinDifferenceFunction,
        fftSimple: yinDifferenceFunctionFFTSimple,
        fftZeroPadding: yinDifferenceFunctionFftZeroPadding,
      };

      function performYinAnalysis(audioBuffer, frameSize, hopSize) {
        // Use parameters from yinParams if not provided
        frameSize = frameSize || yinParams.frameSize;
        hopSize = hopSize || yinParams.hopSize;

        const sampleRate = audioBuffer.sampleRate;
        const audioData = audioBuffer.getChannelData(0);
        const yinResults = [];

        // Performance tracking
        const analysisStartTime = performance.now();
        let frameCount = 0;

        // Select difference function based on method
        const useDifferenceFunction =
          yinDifferenceMethods[yinParams.differenceMethod] ||
          yinDifferenceFunctionFftZeroPadding;

        // Process audio in overlapping frames
        for (let i = 0; i <= audioData.length - frameSize; i += hopSize) {
          const frame = audioData.slice(i, i + frameSize);

          // Step 1: Difference function
          const differenceFunction = useDifferenceFunction(frame);
          frameCount++;

          // Step 2: Cumulative mean normalized difference function
          const cmndf =
            yinCumulativeMeanNormalizedDifference(differenceFunction);

          // Step 3: Absolute threshold using selected method
          const thresholdFunction =
            yinThresholdMethods[yinParams.thresholdMethod] ||
            yinAbsoluteThresholdAdaptive;
          let tauEstimate = thresholdFunction(
            cmndf,
            yinParams.threshold,
            sampleRate,
          );

          let pitch = 0;
          let confidence = 0;

          if (tauEstimate > 0) {
            // Step 4: Parabolic interpolation (if enabled)
            const betterTau = yinParams.interpolation
              ? yinParabolicInterpolation(cmndf, tauEstimate)
              : tauEstimate;

            // Convert tau to frequency
            pitch = sampleRate / betterTau;

            // Confidence is inverse of CMNDF value at the estimated tau
            confidence = 1 - cmndf[Math.round(betterTau)];

            // Filter out unrealistic pitches using dynamic parameters
            if (pitch < yinParams.minFreq || pitch > yinParams.maxFreq) {
              pitch = 0;
              confidence = 0;
            }
          }

          if (yinParams.powerConfidenceAdjust) {
            // Calculate RMS power of the frame
            const framePower = calculateRMSPower(frame);

            // Apply power-based confidence adjustment
            // Low power signals are less reliable for pitch detection
            if (confidence > 0) {
              confidence = adjustConfidenceByPower(confidence, framePower);
            }
          }

          yinResults.push({
            pitch: pitch,
            confidence: confidence,
          });
        }

        // Store performance data
        const totalTime = performance.now() - analysisStartTime;
        console.log(
          `YIN Performance: ${yinParams.differenceMethod} - Total=${totalTime.toFixed(1)}ms, Frames=${frameCount}`,
        );

        return yinResults;
      }

      // --- HELPER FUNCTIONS ---
      // DOM visibility helpers
      function show(element) {
        element.classList.remove("hidden");
      }

      function hide(element) {
        element.classList.add("hidden");
      }

      // Status message helpers
      function setStatus(message, options = {}) {
        const {
          backgroundColor = null,
          isLoading = false,
          spinnerColor = "border-blue-300",
        } = options;

        // Update message text
        instructions.textContent = message;

        // Show/hide spinner
        if (isLoading) {
          // Update spinner color
          replaceClasses(
            statusSpinner,
            ["border-blue-300", "border-purple-300", "border-green-300"],
            [spinnerColor],
          );
          show(statusSpinner);
        } else {
          hide(statusSpinner);
        }

        show(statusDiv);

        if (backgroundColor) {
          statusDiv.style.backgroundColor = backgroundColor;
        }
      }

      function hideStatus() {
        hide(statusDiv);
      }

      // Controls visibility
      function showControls() {
        show(controls);
        show(playButton);
        show(yinControlsSection);
      }

      // Progress line helpers
      function showProgressLine() {
        show(progressLine);
        progressLine.style.left = "0%";
      }

      function hideProgressLine() {
        hide(progressLine);
      }

      function updateProgressLine(percentage) {
        progressLine.style.left = percentage + "%";
      }

      // Text content helpers
      function setText(elementId, text) {
        document.getElementById(elementId).textContent = text;
      }

      // Class manipulation helpers
      function replaceClasses(element, removeClasses, addClasses) {
        element.classList.remove(...removeClasses);
        element.classList.add(...addClasses);
      }

      // Play/Stop button state management
      function showPlayingState() {
        hide(playIcon);
        show(stopIcon);
        playStopButton.title = "Stop audio";
        replaceClasses(
          playStopButton,
          ["bg-blue-600", "hover:bg-blue-500"],
          ["bg-red-600", "hover:bg-red-500"],
        );
      }

      function showStoppedState() {
        show(playIcon);
        hide(stopIcon);
        playStopButton.title = "Play audio";
        replaceClasses(
          playStopButton,
          ["bg-red-600", "hover:bg-red-500"],
          ["bg-blue-600", "hover:bg-blue-500"],
        );
      }

      // --- DISPLAY CONTROLS TOGGLE ---
      function toggleDisplayControls() {
        const displayControls = document.getElementById(
          "displayControlsContent",
        );
        const chevron = document.getElementById("displayControlsChevron");

        if (displayControls.classList.contains("hidden")) {
          // Show controls
          displayControls.classList.remove("hidden");
          displayControls.classList.add("grid");
          chevron.style.transform = "rotate(180deg)";
        } else {
          // Hide controls
          displayControls.classList.remove("grid");
          displayControls.classList.add("hidden");
          chevron.style.transform = "rotate(0deg)";
        }
      }

      // --- YIN CONTROLS TOGGLE ---
      function toggleYinControls() {
        const yinControls = document.getElementById("yinControls");
        const chevron = document.getElementById("yinControlsChevron");

        if (yinControls.classList.contains("hidden")) {
          // Show controls
          yinControls.classList.remove("hidden");
          yinControls.classList.add("grid");
          chevron.style.transform = "rotate(180deg)";
        } else {
          // Hide controls
          yinControls.classList.remove("grid");
          yinControls.classList.add("hidden");
          chevron.style.transform = "rotate(0deg)";
        }
      }

      // --- RECORDING CONTROLS TOGGLE ---
      function toggleRecordingControls() {
        const recordingControls = document.getElementById(
          "recordingControlsContent",
        );
        const chevron = document.getElementById("recordingControlsChevron");

        if (recordingControls.classList.contains("hidden")) {
          // Show controls
          recordingControls.classList.remove("hidden");
          recordingControls.classList.add("grid");
          chevron.style.transform = "rotate(180deg)";
        } else {
          // Hide controls
          recordingControls.classList.remove("grid");
          recordingControls.classList.add("hidden");
          chevron.style.transform = "rotate(0deg)";
        }
      }

      // --- EVENT LISTENERS ---
      window.addEventListener("load", () => {
        hide(controls);
        hide(playButton);
        hideStatus();
        loadAudioFile("audio/ai_讀書寫字.mp3");
      });

      document.addEventListener("keydown", (e) => {
        if (e.code === "Space") {
          e.preventDefault(); // Always prevent space bar scrolling
          if (!isRecording) {
            startRecording();
          }
        } else if (e.code === "Enter" || e.code === "NumpadEnter") {
          e.preventDefault(); // Prevent form submission or other default behavior
          if (lastAudioBuffer && !isRecording) {
            togglePlayStop();
          }
        }
      });

      document.addEventListener("keyup", (e) => {
        if (e.code === "Space") {
          e.preventDefault(); // Always prevent space bar scrolling
          stopRecording();
        }
      });

      window.addEventListener("blur", () => {
        stopRecording();
      });

      window.addEventListener("resize", () => {
        if (spectrogramData.length > 0) {
          drawSpectrogram();
          drawYinPitchChart();
        }
      });

      // --- DRAG AND DROP EVENT LISTENERS ---
      // Counter to track drag enter/leave events for proper overlay handling
      let dragCounter = 0;

      document.body.addEventListener("dragenter", (e) => {
        e.preventDefault();
        dragCounter++;
        show(dropOverlay);
      });

      document.body.addEventListener("dragover", (e) => {
        e.preventDefault();
        e.stopPropagation();
      });

      document.body.addEventListener("dragleave", (e) => {
        e.preventDefault();
        dragCounter--;
        // Only hide when all drag events have left
        if (dragCounter === 0) {
          hide(dropOverlay);
        }
      });

      document.body.addEventListener("drop", (e) => {
        e.preventDefault();
        e.stopPropagation();
        dragCounter = 0;
        hide(dropOverlay);

        const files = e.dataTransfer.files;
        if (files.length > 0) {
          const file = files[0];
          // Check if it's an audio file
          if (file.type.startsWith("audio/")) {
            loadDroppedAudio(file);
          } else {
            setStatus("Please drop an audio file (MP3, WAV, OGG, M4A)", {
              backgroundColor: "#d97706",
            });
          }
        }
      });

      // Generic handler for control setup and updates
      function setupControl(elementOrId, paramsObject, paramKey, config = {}) {
        const {
          eventType = "change",
          parser = (target) => target.value,
          displayElementId = null,
          formatter = (v) => v,
          onChange = null,
        } = config;

        // Support both element and elementId
        const element =
          typeof elementOrId === "string"
            ? document.getElementById(elementOrId)
            : elementOrId;

        const initialValue = paramsObject[paramKey];

        // Initialize the element with the value from params
        if (element.type === "checkbox") {
          element.checked = initialValue;
        } else {
          element.value = initialValue;
        }

        // Initialize display value if provided
        if (displayElementId) {
          setText(displayElementId, formatter(initialValue));
        }

        // Set up event listener for changes
        element.addEventListener(eventType, (e) => {
          const value = parser(e.target);
          paramsObject[paramKey] = value;

          if (displayElementId) {
            setText(displayElementId, formatter(value));
          }

          // Call optional callback
          if (onChange) {
            onChange();
          }
        });
      }

      // Helper function to redraw visualizations if data exists
      function redrawIfDataExists() {
        if (spectrogramData.length > 0) {
          drawSpectrogram();
          drawYinPitchChart();
        }
      }

      // Setup all display controls
      setupControl(colorSchemeSelect, settings, "colorScheme", {
        onChange: redrawIfDataExists,
      });

      setupControl(brightnessSlider, settings, "brightness", {
        eventType: "input",
        parser: (t) => parseInt(t.value, 10),
        displayElementId: "brightnessValue",
        onChange: redrawIfDataExists,
      });

      setupControl(contrastSlider, settings, "contrast", {
        eventType: "input",
        parser: (t) => parseFloat(t.value),
        displayElementId: "contrastValue",
        formatter: (v) => v.toFixed(1),
        onChange: redrawIfDataExists,
      });

      // --- RECORDING SETTINGS CONTROLS ---
      setupControl("recordingSampleRate", recordingSettings, "sampleRate", {
        parser: (t) => parseInt(t.value, 10),
      });

      setupControl("recordingChannelCount", recordingSettings, "channelCount", {
        parser: (t) => parseInt(t.value, 10),
      });

      setupControl(
        "recordingEchoCancellation",
        recordingSettings,
        "echoCancellation",
        {
          parser: (t) => t.checked,
        },
      );

      setupControl(
        "recordingNoiseSuppression",
        recordingSettings,
        "noiseSuppression",
        {
          parser: (t) => t.checked,
        },
      );

      setupControl(
        "recordingAutoGainControl",
        recordingSettings,
        "autoGainControl",
        {
          parser: (t) => t.checked,
        },
      );

      // --- YIN PARAMETER EVENT LISTENERS ---
      function recomputeYin() {
        if (lastAudioBuffer && yinData.length > 0) {
          showYinPitchLoadingOverlay();
          // Use setTimeout to allow browser to repaint and show the overlay
          setTimeout(() => {
            yinData = performYinAnalysis(lastAudioBuffer);
            drawYinPitchChart();
            hideYinPitchLoadingOverlay();
          }, 10);
        }
      }

      function showYinPitchLoadingOverlay() {
        show(yinPitchLoadingOverlay);
      }

      function hideYinPitchLoadingOverlay() {
        hide(yinPitchLoadingOverlay);
      }

      // Setup all YIN parameter controls
      setupControl("yinFrameSize", yinParams, "frameSize", {
        parser: (t) => parseInt(t.value, 10),
        onChange: recomputeYin,
      });

      setupControl("yinHopSize", yinParams, "hopSize", {
        parser: (t) => parseInt(t.value, 10),
        onChange: recomputeYin,
      });

      setupControl("yinThresholdSlider", yinParams, "threshold", {
        eventType: "input",
        parser: (t) => parseFloat(t.value),
        displayElementId: "yinThresholdValue",
        formatter: (v) => v.toFixed(2),
        onChange: recomputeYin,
      });

      setupControl(
        "yinFallbackThresholdSlider",
        yinParams,
        "fallbackThreshold",
        {
          eventType: "input",
          parser: (t) => parseFloat(t.value),
          displayElementId: "yinFallbackThresholdValue",
          formatter: (v) => v.toFixed(2),
          onChange: recomputeYin,
        },
      );

      setupControl("yinMinFreqSlider", yinParams, "minFreq", {
        eventType: "input",
        parser: (t) => parseInt(t.value, 10),
        displayElementId: "yinMinFreqValue",
        onChange: recomputeYin,
      });

      setupControl("yinMaxFreqSlider", yinParams, "maxFreq", {
        eventType: "input",
        parser: (t) => parseInt(t.value, 10),
        displayElementId: "yinMaxFreqValue",
        onChange: recomputeYin,
      });

      setupControl("yinInterpolation", yinParams, "interpolation", {
        parser: (t) => t.checked,
        onChange: recomputeYin,
      });

      setupControl("yinDifferenceMethod", yinParams, "differenceMethod", {
        onChange: recomputeYin,
      });

      setupControl("yinThresholdMethod", yinParams, "thresholdMethod", {
        onChange: recomputeYin,
      });

      setupControl(
        "yinPowerConfidenceAdjust",
        yinParams,
        "powerConfidenceAdjust",
        {
          parser: (t) => t.checked,
          onChange: recomputeYin,
        },
      );

      setupControl(
        "yinMinPowerThresholdSlider",
        yinParams,
        "minPowerThreshold",
        {
          eventType: "input",
          parser: (t) => parseFloat(t.value),
          displayElementId: "yinMinPowerThresholdValue",
          formatter: (v) => v.toFixed(3),
          onChange: recomputeYin,
        },
      );

      // --- CORE AUDIO FUNCTIONS ---

      /**
       * Ensures AudioContext is initialized with proper sample rate
       */
      function ensureAudioContext() {
        if (!audioContext) {
          audioContext = new (window.AudioContext || window.webkitAudioContext)(
            { sampleRate: RECORDING_SAMPLE_RATE },
          );
        }
        return audioContext;
      }

      /**
       * Common workflow for processing audio buffer:
       * - Performs YIN analysis
       * - Generates spectrogram
       * - Updates UI
       * - Auto-plays audio
       */
      async function processAudioBuffer(audioBuffer) {
        // Store for replay
        lastAudioBuffer = audioBuffer;

        // Initialize data arrays
        yinData = [];

        // Update status for YIN analysis
        setStatus("Computing YIN pitch analysis...", {
          isLoading: true,
          spinnerColor: "border-purple-300",
        });

        // Perform YIN analysis
        yinData = performYinAnalysis(audioBuffer);

        // Update status for spectrogram
        setStatus("Generating spectrogram...", {
          isLoading: true,
          spinnerColor: "border-green-300",
        });

        // Analyze and draw visualizations
        analyzeAndDraw(audioBuffer);

        hideStatus();

        // Show controls and play button
        showControls();

        // Auto-play the audio
        playLastRecording();
      }

      async function startRecording() {
        if (isRecording) {
          return;
        }
        isRecording = true;
        audioChunks = [];

        try {
          // Ensure AudioContext is created by user gesture with high sample rate
          ensureAudioContext();

          const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
              channelCount: { ideal: recordingSettings.channelCount },
              sampleRate: { ideal: recordingSettings.sampleRate },
              echoCancellation: recordingSettings.echoCancellation,
              noiseSuppression: recordingSettings.noiseSuppression,
              autoGainControl: recordingSettings.autoGainControl,
              latency: 0, // Request lowest possible latency
            },
          });
          if (!stream) {
            return;
          }
          if (!isRecording) {
            stream.getAudioTracks().forEach((track) => track.stop());
            return;
          }
          mediaRecorder = new MediaRecorder(stream);
          mediaRecorder.onstart = (event) => {
            setStatus("Recording...", { backgroundColor: "#ef4444" });
          };
          mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
          };
          mediaRecorder.onstop = processAudio;
          mediaRecorder.start();
        } catch (err) {
          console.error("Error accessing microphone:", err);
          setStatus(
            "Microphone access denied. Please allow access and try again.",
            { backgroundColor: "#d97706" },
          );
          isRecording = false;
        }
      }

      function stopRecording() {
        if (!isRecording) {
          return;
        }
        isRecording = false;
        if (!mediaRecorder) {
          return;
        }
        mediaRecorder.stop();

        // Clean up media stream tracks
        if (mediaRecorder.stream) {
          mediaRecorder.stream.getTracks().forEach((track) => track.stop());
        }

        setStatus("Analyzing...", { backgroundColor: "#3b82f6" });
        showYinPitchLoadingOverlay();
      }

      function processAudio() {
        const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
        const reader = new FileReader();
        reader.onload = async (e) => {
          try {
            const audioBuffer = await audioContext.decodeAudioData(
              e.target.result,
            );
            hideYinPitchLoadingOverlay();
            await processAudioBuffer(audioBuffer);
          } catch (err) {
            console.error("Error decoding audio data:", err);
            setStatus("Could not process audio. Please try again.");
          }
        };
        reader.readAsArrayBuffer(audioBlob);
      }

      async function playAudio(audioBuffer) {
        // Stop any currently playing audio and clear existing animation frame
        if (currentAudioSource) {
          try {
            currentAudioSource.stop();
          } catch (e) {
            // Ignore errors if source already stopped
          }
        }
        if (progressAnimationFrame) {
          cancelAnimationFrame(progressAnimationFrame);
          progressAnimationFrame = null;
        }

        // Resume AudioContext if suspended (required for some browsers)
        if (audioContext.state === "suspended") {
          await audioContext.resume();
        }

        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(audioContext.destination);

        // Show progress line
        showProgressLine();

        audioDuration = audioBuffer.duration;

        currentAudioSource = source;
        isPlaying = true;
        updatePlayStopButton();

        // Use performance.now() for more accurate progress tracking
        let playbackStartTime = null;

        // Start progress tracking using requestAnimationFrame for smooth updates
        function updateProgress() {
          if (!isPlaying) {
            progressAnimationFrame = null;
            return;
          }

          // Initialize start time on first frame (when audio has actually started)
          if (playbackStartTime === null) {
            playbackStartTime = performance.now();
          }

          // Calculate elapsed time in seconds using high-resolution timer
          const elapsed = (performance.now() - playbackStartTime) / 1000;
          const progress = Math.min((elapsed / audioDuration) * 100, 100);

          updateProgressLine(progress);

          if (progress >= 100 || elapsed >= audioDuration) {
            isPlaying = false;
            currentAudioSource = null;
            updatePlayStopButton();
            updateProgressLine(100);
            progressAnimationFrame = null;
            // Keep progress line visible briefly after completion
            setTimeout(() => {
              if (!isPlaying) {
                hideProgressLine();
              }
            }, 1000);
          } else {
            progressAnimationFrame = requestAnimationFrame(updateProgress);
          }
        }

        source.onended = () => {
          if (progressAnimationFrame) {
            cancelAnimationFrame(progressAnimationFrame);
            progressAnimationFrame = null;
          }
          isPlaying = false;
          currentAudioSource = null;
          updatePlayStopButton();
          hideProgressLine();
        };

        // Start the audio immediately
        source.start(0);

        // Start the progress animation
        progressAnimationFrame = requestAnimationFrame(updateProgress);
      }

      function playLastRecording() {
        if (lastAudioBuffer && audioContext) {
          playAudio(lastAudioBuffer);
        }
      }

      function stopPlayback() {
        if (currentAudioSource) {
          try {
            currentAudioSource.stop();
          } catch (e) {
            // Ignore errors if source already stopped
          }
          currentAudioSource = null;
        }
        if (progressAnimationFrame) {
          cancelAnimationFrame(progressAnimationFrame);
          progressAnimationFrame = null;
        }
        isPlaying = false;
        hideProgressLine();
        updatePlayStopButton();
      }

      function togglePlayStop() {
        if (isPlaying) {
          stopPlayback();
        } else {
          playLastRecording();
        }
      }

      function updatePlayStopButton() {
        if (isPlaying) {
          showPlayingState();
        } else {
          showStoppedState();
        }
      }

      async function loadDroppedAudio(file) {
        try {
          // Stop any currently playing audio
          if (isPlaying) {
            stopPlayback();
          }

          // Show loading indicator
          setStatus("Processing audio file...", {
            backgroundColor: "#3b82f6",
            isLoading: true,
            spinnerColor: "border-blue-300",
          });

          // Initialize audio context
          ensureAudioContext();

          // Read file as array buffer
          const arrayBuffer = await file.arrayBuffer();

          // Decode audio data
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

          // Process the audio buffer (YIN analysis, spectrogram, UI updates, auto-play)
          await processAudioBuffer(audioBuffer);
        } catch (err) {
          console.error("Error loading dropped audio:", err);
          setStatus(
            "Could not process audio file. Make sure it's a valid audio format.",
            {
              backgroundColor: "#d97706",
            },
          );
        }
      }

      async function loadAudioFile(filePath, needMaxFreq = null) {
        try {
          // Stop any currently playing audio
          if (isPlaying) {
            stopPlayback();
          }

          // Scroll to top of page
          window.scrollTo({ top: 0, behavior: "smooth" });

          // Adjust Max Freq if a minimum is specified and current value is lower
          if (needMaxFreq !== null && yinParams.maxFreq !== needMaxFreq) {
            yinParams.maxFreq = needMaxFreq;
            document.getElementById("yinMaxFreqSlider").value = needMaxFreq;
            setText("yinMaxFreqValue", needMaxFreq.toString());
          }

          // Show loading indicator
          setStatus("Loading audio file...", {
            backgroundColor: "#3b82f6",
            isLoading: true,
            spinnerColor: "border-blue-300",
          });

          // Initialize audio context
          ensureAudioContext();

          // Fetch the audio file
          const response = await fetch(filePath);
          if (!response.ok) {
            throw new Error(
              `Failed to load audio file: ${response.statusText}`,
            );
          }

          // Read as array buffer
          const arrayBuffer = await response.arrayBuffer();

          // Decode audio data
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

          // Process the audio buffer (YIN analysis, spectrogram, UI updates, auto-play)
          await processAudioBuffer(audioBuffer);
        } catch (err) {
          console.error("Error loading audio file:", err);
          setStatus("Could not load audio file. Please try again.", {
            backgroundColor: "#d97706",
          });
        }
      }

      function analyzeAndDraw(audioBuffer) {
        const offlineCtx = new OfflineAudioContext(
          audioBuffer.numberOfChannels,
          audioBuffer.length,
          audioBuffer.sampleRate,
        );
        const source = offlineCtx.createBufferSource();
        source.buffer = audioBuffer;

        const analyser = offlineCtx.createAnalyser();
        analyser.fftSize = FFT_SIZE; // Use the new higher resolution FFT size
        analyser.smoothingTimeConstant = 0;

        // Decreased buffer size for better time (horizontal) resolution.
        const bufferSize = BUFFER_SIZE;
        const processor = offlineCtx.createScriptProcessor(bufferSize, 1, 1);

        const freqData = new Uint8Array(analyser.frequencyBinCount);
        spectrogramData = [];

        processor.onaudioprocess = (e) => {
          analyser.getByteFrequencyData(freqData);
          spectrogramData.push(new Uint8Array(freqData));
        };

        source.connect(analyser);
        analyser.connect(processor);
        processor.connect(offlineCtx.destination);

        source.start(0);

        offlineCtx
          .startRendering()
          .then(() => {
            hideStatus();
            showControls();

            drawSpectrogram();
            drawYinPitchChart();
          })
          .catch((err) => {
            console.error("Offline rendering failed:", err);
            setStatus("Error during analysis.");
          });
      }

      function drawSpectrogram() {
        const numSlices = spectrogramData.length;
        if (numSlices === 0) return;

        // --- EDITED FOR FOCUSED VIEW ---
        // Calculate how many frequency bins to show to focus on the vocal range.
        const freqPerBin = audioContext.sampleRate / FFT_SIZE;
        const relevantBins = Math.ceil(MAX_FREQ_HZ / freqPerBin);
        const totalBins = spectrogramData[0].length;
        const finalBinsToDraw = Math.min(relevantBins, totalBins);

        canvas.width = numSlices;
        canvas.height = finalBinsToDraw;

        const imageData = canvasCtx.createImageData(
          canvas.width,
          canvas.height,
        );
        const data = imageData.data;

        for (let x = 0; x < canvas.width; x++) {
          for (let y = 0; y < canvas.height; y++) {
            const value = spectrogramData[x][y];
            const color = getColor(value, settings.colorScheme);

            let r =
              settings.contrast * (color[0] - 128) + 128 + settings.brightness;
            let g =
              settings.contrast * (color[1] - 128) + 128 + settings.brightness;
            let b =
              settings.contrast * (color[2] - 128) + 128 + settings.brightness;

            r = Math.max(0, Math.min(255, r));
            g = Math.max(0, Math.min(255, g));
            b = Math.max(0, Math.min(255, b));

            const pixelIndex = ((canvas.height - 1 - y) * canvas.width + x) * 4;
            data[pixelIndex] = r;
            data[pixelIndex + 1] = g;
            data[pixelIndex + 2] = b;
            data[pixelIndex + 3] = 255;
          }
        }
        canvasCtx.putImageData(imageData, 0, 0);
      }

      function drawYinPitchChart() {
        if (yinData.length === 0) return;
        if (!lastAudioBuffer) return;

        // Get display dimensions from CSS
        const displayWidth = yinPitchCanvas.clientWidth;
        const displayHeight = yinPitchCanvas.clientHeight;
        const pixelRatio = window.devicePixelRatio || 1;

        // Set high-resolution canvas dimensions
        yinPitchCanvas.width = displayWidth * pixelRatio;
        yinPitchCanvas.height = displayHeight * pixelRatio;

        // Scale context for high-DPI rendering
        yinPitchCanvasCtx.setTransform(pixelRatio, 0, 0, pixelRatio, 0, 0);

        const ctx = yinPitchCanvasCtx;
        const width = displayWidth;
        const height = displayHeight;

        // Clear canvas with transparent background
        ctx.clearRect(0, 0, width, height);

        const validPitches = yinData.filter((frame) => frame.pitch > 0);
        if (validPitches.length > 0) {
          const minPitch = Math.min(
            yinParams.minFreq,
            ...validPitches.map((f) => f.pitch),
          );
          const maxPitch = Math.max(...validPitches.map((f) => f.pitch));
          const pitchRange = Math.max(maxPitch - minPitch, 50);

          // Draw pitch line with confidence-based opacity
          ctx.lineWidth = 2 * YIN_PITCH_LINE_WIDTH;

          // Maximum vertical jump threshold
          const maxJumpThreshold = height * YIN_MAX_JUMP_THRESHOLD_PERCENT;

          // Calculate time-based alignment with spectrogram
          const sampleRate = lastAudioBuffer.sampleRate;
          const totalDuration = lastAudioBuffer.duration;

          // The spectrogram uses FFT analysis with a window, creating a delay
          // Account for spectrogram's FFT window delay (FFT_SIZE/2)
          const spectrogramDelay = FFT_SIZE / 2;

          let lastValidX = -1;
          let lastValidY = -1;
          let lastValidAlpha = -1;

          for (let i = 0; i < yinData.length; i++) {
            const frame = yinData[i];
            if (frame.pitch > 0) {
              // Calculate actual time position of this YIN frame
              // Frame starts at sample: i * hopSize
              // YIN frames are centered at their midpoint: i * hopSize + frameSize/2
              const frameStartSample = i * yinParams.hopSize;
              const frameCenterSample =
                frameStartSample + yinParams.frameSize / 2;

              // Adjust for spectrogram's FFT delay to align properly
              const adjustedSample = frameCenterSample + spectrogramDelay;
              const timeInSeconds = adjustedSample / sampleRate;

              // Map time to canvas width to align with spectrogram
              const x = (timeInSeconds / totalDuration) * width;

              // Map pitch to independent Y-axis (full canvas height for pitch range)
              const pitchRatio = (frame.pitch - minPitch) / pitchRange;
              const y = height - pitchRatio * height;

              // Color based on confidence with bright, visible colors
              const alpha = frame.confidence;

              ctx.fillStyle = `rgba(255, 255, 255, ${alpha})`;

              // Draw line connecting consecutive valid pitch points only if jump is small enough
              if (lastValidX >= 0 && lastValidY >= 0) {
                const verticalJump = Math.abs(y - lastValidY);

                // Only draw connecting line if the jump is below threshold
                if (verticalJump < maxJumpThreshold) {
                  // Use bright yellow/white for high visibility over spectrogram
                  const strokeAlpha = Math.min(
                    lastValidAlpha,
                    frame.confidence,
                  );
                  ctx.strokeStyle = `rgba(255, 255, 255, ${strokeAlpha})`;

                  ctx.beginPath();
                  ctx.moveTo(lastValidX, lastValidY);
                  ctx.lineTo(x, y);
                  ctx.stroke();
                }
              }

              ctx.beginPath();
              ctx.arc(x, y, YIN_PITCH_POINT_RADIUS, 0, 2 * Math.PI);
              ctx.fill();

              lastValidX = x;
              lastValidY = y;
              lastValidAlpha = alpha;
            } else {
              // Reset line drawing when pitch is invalid
              lastValidX = -1;
              lastValidY = -1;
            }
          }

          // Draw pitch range labels on the overlay
          ctx.fillStyle = "rgba(255, 255, 255, 0.9)";
          ctx.font = "12px Inter";
          ctx.textAlign = "left";
          ctx.fillText(`${Math.round(maxPitch)}Hz`, 5, 20);
          ctx.fillText(`${Math.round(minPitch)}Hz`, 5, height - 10);
        } else {
          ctx.fillStyle = "#9CA3AF";
          ctx.font = "14px Inter";
          ctx.textAlign = "center";
          ctx.fillText("No pitch detected", width / 2, height / 2);
        }
      }
    </script>
    <script src="fftjs.min.js"></script>
  </body>
</html>
