<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tone Analyzer for Mandarin Practice</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
      }
      /* Style for the canvas to make it responsive and sharp */
      canvas {
        width: 100%;
        height: 300px;
        background-color: #111827; /* bg-gray-900 */
        border-radius: 0.5rem;
        image-rendering: -moz-crisp-edges;
        image-rendering: -webkit-crisp-edges;
        image-rendering: pixelated;
        image-rendering: crisp-edges;
      }
      /* Custom styles for range sliders */
      input[type="range"] {
        -webkit-appearance: none;
        appearance: none;
        width: 100%;
        height: 8px;
        background: #4b5563; /* bg-gray-600 */
        border-radius: 5px;
        outline: none;
        opacity: 0.7;
        transition: opacity 0.2s;
      }
      input[type="range"]:hover {
        opacity: 1;
      }
      input[type="range"]::-webkit-slider-thumb {
        -webkit-appearance: none;
        appearance: none;
        width: 20px;
        height: 20px;
        background: #3b82f6; /* bg-blue-500 */
        cursor: pointer;
        border-radius: 50%;
      }
      input[type="range"]::-moz-range-thumb {
        width: 20px;
        height: 20px;
        background: #3b82f6; /* bg-blue-500 */
        cursor: pointer;
        border-radius: 50%;
      }
    </style>
  </head>
  <body
    class="bg-gray-800 text-gray-200 flex flex-col items-center justify-center min-h-screen p-4"
  >
    <div class="w-full max-w-4xl mx-auto">
      <div class="text-center mb-6">
        <h1 class="text-3xl md:text-4xl font-bold text-white">Tone Analyzer</h1>
      </div>

      <!-- Status Message -->
      <div
        id="status"
        class="text-center mb-4 p-3 rounded-lg bg-gray-700 transition-all duration-300"
      >
        <p id="instructions" class="text-lg font-medium text-blue-300">
          Loading...
        </p>
      </div>

      <!-- UI Controls -->
      <div
        id="controls"
        class="mt-6 grid grid-cols-1 md:grid-cols-4 gap-6 bg-gray-700/50 p-6 rounded-lg"
      >
        <div>
          <label
            for="colorScheme"
            class="block mb-2 text-sm font-medium text-gray-300"
            >Color Scheme</label
          >
          <select
            id="colorScheme"
            class="bg-gray-600 border border-gray-500 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-1"
          >
            <option value="viridis">Viridis</option>
            <option value="plasma">Plasma</option>
            <option value="hot">Hot</option>
            <option value="grayscale">Grayscale</option>
          </select>
        </div>
        <div>
          <label
            for="brightness"
            class="block mb-2 text-sm font-medium text-gray-300"
            >Brightness</label
          >
          <input
            type="range"
            id="brightness"
            min="-100"
            max="100"
            value="-50"
            class="w-full"
          />
        </div>
        <div>
          <label
            for="contrast"
            class="block mb-2 text-sm font-medium text-gray-300"
            >Contrast</label
          >
          <input
            type="range"
            id="contrast"
            min="0"
            max="5"
            value="1.5"
            step="0.1"
            class="w-full"
          />
        </div>
      </div>

      <!-- Spectrogram Canvas with YIN Pitch Overlay -->
      <div class="w-full bg-gray-900 rounded-lg shadow-lg p-2 relative">
        <div class="relative">
          <canvas id="spectrogramCanvas"></canvas>
          <canvas
            id="yinPitchCanvas"
            class="absolute top-0 left-0 pointer-events-none"
            style="background: transparent"
          ></canvas>
          <div
            id="progressLine"
            class="absolute top-0 w-0.5 bg-white opacity-90 pointer-events-none hidden"
            style="height: 100%; left: 0%; transition: left 0.1s linear"
          ></div>
        </div>
        <div
          id="loadingOverlay"
          class="absolute inset-0 bg-gray-900/80 flex items-center justify-center rounded-lg hidden"
        >
          <div class="text-center">
            <div
              class="animate-spin rounded-full h-8 w-8 border-b-2 border-blue-500 mx-auto mb-2"
            ></div>
            <p class="text-gray-300 text-sm">Computing charts...</p>
          </div>
        </div>
        <div
          id="yinPitchLoadingOverlay"
          class="absolute inset-0 bg-gray-900/80 flex items-center justify-center rounded-lg hidden"
        >
          <div class="text-center">
            <div
              class="animate-spin rounded-full h-8 w-8 border-b-2 border-purple-500 mx-auto mb-2"
            ></div>
            <p class="text-gray-300 text-sm">Computing YIN pitch...</p>
          </div>
        </div>
        <!-- Play Button -->
        <div id="playButton" class="flex justify-center mt-3">
          <div class="w-64">&nbsp;</div>
          <button
            onclick="playLastRecording()"
            class="flex items-center justify-center w-12 h-12 bg-blue-600 hover:bg-blue-500 rounded-full transition-colors duration-200 shadow-lg"
            title="Play audio"
          >
            <svg
              class="w-6 h-6 text-white ml-0.5"
              fill="currentColor"
              viewBox="0 0 24 24"
            >
              <path d="M8 5v14l11-7z" />
            </svg>
          </button>
          <div class="p-3.5">
            or press
            <kbd
              class="px-2 py-1.5 text-xs font-semibold text-gray-800 bg-gray-100 border border-gray-200 rounded-lg"
              >Enter</kbd
            >
            to play, hold
            <kbd
              class="px-2 py-1.5 text-xs font-semibold text-gray-800 bg-gray-100 border border-gray-200 rounded-lg"
              >Space</kbd
            >
            to record.
          </div>
        </div>
      </div>

      <!-- Algorithm Controls -->
      <div id="yinControlsSection" class="mt-4 hidden">
        <!-- YIN Controls -->
        <div class="mb-2">
          <h4 class="text-yellow-400 text-sm font-medium mb-2">YIN Algorithm parameters:</h4>

          <div
            id="yinControls"
            class="grid grid-cols-2 md:grid-cols-3 lg:grid-cols-6 gap-4 bg-gray-700/50 p-4 rounded-lg"
        >
          <div>
            <label
              for="yinFrameSize"
              class="block mb-2 text-xs font-medium text-gray-300"
              >Frame Size</label
            >
            <select
              id="yinFrameSize"
              class="bg-gray-600 border border-gray-500 text-white text-xs rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-1"
            >
              <option value="16">16</option>
              <option value="32">32</option>
              <option value="64">64</option>
              <option value="128">128</option>
              <option value="256">256</option>
              <option value="512">512</option>
              <option value="1024">1024</option>
              <option value="2048" selected>2048</option>
              <option value="4096">4096</option>
            </select>
          </div>
          <div>
            <label
              for="yinHopSize"
              class="block mb-2 text-xs font-medium text-gray-300"
              >Hop Size</label
            >
            <select
              id="yinHopSize"
              class="bg-gray-600 border border-gray-500 text-white text-xs rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-1"
            >
              <option value="4">4</option>
              <option value="8">8</option>
              <option value="16">16</option>
              <option value="32">32</option>
              <option value="64">64</option>
              <option value="128" selected>128</option>
              <option value="256">256</option>
              <option value="512">512</option>
              <option value="1024">1024</option>
              <option value="2048">2048</option>
              <option value="4096">4096</option>
            </select>
          </div>
          <div>
            <label
              for="yinThreshold"
              class="block mb-2 text-xs font-medium text-gray-300"
              >Threshold</label
            >
            <input
              type="range"
              id="yinThresholdSlider"
              min="0.05"
              max="0.9"
              value="0.30"
              step="0.01"
              class="w-full"
            />
            <div
              class="text-xs text-gray-400 text-center mt-1"
              id="yinThresholdValue"
            >
              0.30
            </div>
          </div>
          <div>
            <label
              for="yinMinFreq"
              class="block mb-2 text-xs font-medium text-gray-300"
              >Min Freq (Hz)</label
            >
            <input
              type="range"
              id="yinMinFreqSlider"
              min="10"
              max="200"
              value="30"
              step="5"
              class="w-full"
            />
            <div
              class="text-xs text-gray-400 text-center mt-1"
              id="yinMinFreqValue"
            >
              10
            </div>
          </div>
          <div>
            <label
              for="yinMaxFreq"
              class="block mb-2 text-xs font-medium text-gray-300"
              >Max Freq (Hz)</label
            >
            <input
              type="range"
              id="yinMaxFreqSlider"
              min="100"
              max="1000"
              value="300"
              step="10"
              class="w-full"
            />
            <div
              class="text-xs text-gray-400 text-center mt-1"
              id="yinMaxFreqValue"
            >
              300
            </div>
          </div>
          <div class="flex items-center">
            <input
              type="checkbox"
              id="yinInterpolation"
              checked
              class="w-4 h-4 text-blue-600 bg-gray-700 border-gray-600 rounded focus:ring-blue-500"
            />
            <label
              for="yinInterpolation"
              class="ml-2 text-xs font-medium text-gray-300"
              >Parabolic Interpolation</label
            >
          </div>
        </div>
      </div>
    </div>

    <script src="audio.js"></script>
    <script>
      // Preloaded audio data
      const PRELOADED_AUDIO_DATA = window.PRELOADED_AUDIO_DATA;

      // DOM Elements
      const instructions = document.getElementById("instructions");
      const statusDiv = document.getElementById("status");
      const canvas = document.getElementById("spectrogramCanvas");
      const canvasCtx = canvas.getContext("2d");
      const progressLine = document.getElementById("progressLine");
      const yinPitchCanvas = document.getElementById("yinPitchCanvas");
      const yinPitchCanvasCtx = yinPitchCanvas.getContext("2d");
      const controls = document.getElementById("controls");
      const playButton = document.getElementById("playButton");
      const colorSchemeSelect = document.getElementById("colorScheme");
      const brightnessSlider = document.getElementById("brightness");
      const contrastSlider = document.getElementById("contrast");
      const loadingOverlay = document.getElementById("loadingOverlay");
      const yinPitchLoadingOverlay = document.getElementById(
        "yinPitchLoadingOverlay"
      );

      // Audio & State Variables
      let audioContext;
      let mediaRecorder;
      let isRecording = false;
      let audioChunks = [];
      let spectrogramData = [];
      let yinData = [];
      let lastAudioBuffer = null;
      let yinPerformanceData = { totalDiffTime: 0, totalTime: 0, frameCount: 0 };
      let currentAudioSource = null;
      let isPlaying = false;
      let playStartTime = 0;

      // Visualization Settings
      let settings = {
        colorScheme: "viridis",
        brightness: -50,
        contrast: 1.5,
      };

      // YIN Algorithm Parameters
      let yinParams = {
        frameSize: 2048, // Window size for analysis
        hopSize: 128, // Step size between frames
        threshold: 0.3, // Absolute threshold for period detection
        minFreq: 30, // Minimum frequency to consider (Hz)
        maxFreq: 300, // Maximum frequency to consider (Hz)
        interpolation: true, // Enable parabolic interpolation
      };

      // --- ANALYSIS CONSTANTS (EDITED FOR HIGHER RESOLUTION) ---
      // Increased FFT_SIZE for better frequency (vertical) resolution.
      const FFT_SIZE = 4096 * 2;
      // The maximum frequency (in Hz) to display. This focuses the view on the vocal range.
      const MAX_FREQ_HZ = 1300;
      // is about how often we do the analysis. The system collects audio into a buffer, and every time the buffer is full, it runs the analysis.
      const BUFFER_SIZE = 256;

      // --- COLOR MAPS ---
      const COLOR_MAPS = {
        viridis: [
          [68, 1, 84],
          [72, 40, 120],
          [62, 74, 137],
          [49, 104, 142],
          [38, 130, 142],
          [31, 158, 137],
          [53, 183, 121],
          [109, 205, 89],
          [180, 222, 44],
          [253, 231, 37],
        ],
        plasma: [
          [13, 8, 135],
          [72, 1, 163],
          [120, 1, 168],
          [163, 29, 151],
          [201, 62, 122],
          [230, 99, 90],
          [249, 139, 64],
          [254, 183, 43],
          [240, 226, 33],
        ],
        hot: [
          [0, 0, 0],
          [255, 0, 0],
          [255, 255, 0],
          [255, 255, 255],
        ],
        grayscale: [
          [0, 0, 0],
          [255, 255, 255],
        ],
      };

      function interpolateColor(c1, c2, factor) {
        const result = c1.slice();
        for (let i = 0; i < 3; i++) {
          result[i] = Math.round(result[i] + factor * (c2[i] - result[i]));
        }
        return result;
      }

      function getColor(value, schemeName) {
        const map = COLOR_MAPS[schemeName];
        const scaledValue = (value / 255) * (map.length - 1);
        const colorIndex = Math.floor(scaledValue);
        const factor = scaledValue - colorIndex;

        if (colorIndex >= map.length - 1) {
          return map[map.length - 1];
        }
        return interpolateColor(map[colorIndex], map[colorIndex + 1], factor);
      }

      // --- YIN ALGORITHM IMPLEMENTATION ---
      function yinDifferenceFunction(buffer) {
        const bufferSize = buffer.length;
        const differenceFunction = new Array(bufferSize / 2);

        // Step 1: Difference function d_t(τ) = Σ(x_j - x_{j+τ})²
        for (let tau = 0; tau < bufferSize / 2; tau++) {
          let sum = 0;
          for (let j = 0; j < bufferSize / 2; j++) {
            const delta = buffer[j] - buffer[j + tau];
            sum += delta * delta;
          }
          differenceFunction[tau] = sum;
        }

        return differenceFunction;
      }

      function yinCumulativeMeanNormalizedDifference(differenceFunction) {
        const cmndf = new Array(differenceFunction.length);
        cmndf[0] = 1;

        // Step 2: Cumulative mean normalized difference function
        // d'_t(τ) = { 1 if τ = 0
        //           { d_t(τ) / ((1/τ) * Σ_{j=1}^τ d_t(j)) if τ ≠ 0
        let runningSum = 0;
        for (let tau = 1; tau < differenceFunction.length; tau++) {
          runningSum += differenceFunction[tau];
          cmndf[tau] = differenceFunction[tau] / (runningSum / tau);
        }

        return cmndf;
      }

      function yinAbsoluteThreshold(cmndf, threshold) {
        // Step 3: Absolute threshold
        // Find the first minimum below the threshold
        for (let tau = 2; tau < cmndf.length; tau++) {
          if (cmndf[tau] < threshold) {
            // Check if this is a local minimum
            while (tau + 1 < cmndf.length && cmndf[tau + 1] < cmndf[tau]) {
              tau++;
            }
            return tau;
          }
        }
        return -1; // No period found
      }

      function yinParabolicInterpolation(cmndf, tauEstimate) {
        // Step 4: Parabolic interpolation for better accuracy
        if (tauEstimate < 1 || tauEstimate >= cmndf.length - 1) {
          return tauEstimate;
        }

        const s0 = cmndf[tauEstimate - 1];
        const s1 = cmndf[tauEstimate];
        const s2 = cmndf[tauEstimate + 1];

        // Parabolic interpolation formula
        const betterTau = tauEstimate + (s2 - s0) / (2 * (2 * s1 - s2 - s0));
        return betterTau;
      }

      function performYinAnalysis(audioBuffer, frameSize, hopSize) {
        // Use parameters from yinParams if not provided
        frameSize = frameSize || yinParams.frameSize;
        hopSize = hopSize || yinParams.hopSize;

        const sampleRate = audioBuffer.sampleRate;
        const audioData = audioBuffer.getChannelData(0);
        const yinResults = [];

        // Performance tracking
        const analysisStartTime = performance.now();
        let totalDiffTime = 0;
        let frameCount = 0;

        // Process audio in overlapping frames
        for (let i = 0; i <= audioData.length - frameSize; i += hopSize) {
          const frame = audioData.slice(i, i + frameSize);

          // Step 1: Difference function (with timing)
          const diffStartTime = performance.now();
          const differenceFunction = yinDifferenceFunction(frame);
          totalDiffTime += performance.now() - diffStartTime;
          frameCount++;

          // Step 2: Cumulative mean normalized difference function
          const cmndf =
            yinCumulativeMeanNormalizedDifference(differenceFunction);

          // Step 3: Absolute threshold
          let tauEstimate = yinAbsoluteThreshold(cmndf, yinParams.threshold);

          let pitch = 0;
          let confidence = 0;

          if (tauEstimate > 0) {
            // Step 4: Parabolic interpolation (if enabled)
            const betterTau = yinParams.interpolation
              ? yinParabolicInterpolation(cmndf, tauEstimate)
              : tauEstimate;

            // Convert tau to frequency
            pitch = sampleRate / betterTau;

            // Confidence is inverse of CMNDF value at the estimated tau
            confidence = 1 - cmndf[Math.round(betterTau)];

            // Filter out unrealistic pitches using dynamic parameters
            if (pitch < yinParams.minFreq || pitch > yinParams.maxFreq) {
              pitch = 0;
              confidence = 0;
            }
          }

          yinResults.push({
            pitch: pitch,
            confidence: confidence,
            differenceFunction: differenceFunction.slice(0, 200), // Store first 200 points for visualization
            cmndf: cmndf.slice(0, 200),
            tau: tauEstimate,
            threshold: yinParams.threshold,
            timeIndex: i / sampleRate,
          });
        }

        // Store performance data
        const totalTime = performance.now() - analysisStartTime;
        yinPerformanceData = {
          totalDiffTime: totalDiffTime,
          totalTime: totalTime,
          frameCount: frameCount
        };

        console.log(`YIN Performance: Total=${totalTime.toFixed(1)}ms, Diff total=${totalDiffTime.toFixed(1)}ms, Frames=${frameCount}`);

        return yinResults;
      }

      // --- EVENT LISTENERS ---
      window.addEventListener("load", () => {
        controls.style.display = "none";
        playButton.style.display = "none";
        instructions.innerHTML = getDefaultInstructions();
        // Automatically load and process the preloaded audio
        loadPreloadedAudio();
      });

      document.addEventListener("keydown", (e) => {
        if (e.code === "Space") {
          e.preventDefault(); // Always prevent space bar scrolling
          if (!isRecording) {
            startRecording();
          }
        } else if (e.code === "Enter" || e.code === "NumpadEnter") {
          e.preventDefault(); // Prevent form submission or other default behavior
          if (lastAudioBuffer && !isRecording) {
            playLastRecording();
          }
        }
      });

      document.addEventListener("keyup", (e) => {
        if (e.code === "Space") {
          e.preventDefault(); // Always prevent space bar scrolling
          if (isRecording) {
            stopRecording();
          }
        }
      });

      colorSchemeSelect.addEventListener("change", (e) => {
        settings.colorScheme = e.target.value;
        if (spectrogramData.length > 0) {
          drawSpectrogram();
          drawYinPitchChart();
        }
      });
      brightnessSlider.addEventListener("input", (e) => {
        settings.brightness = parseInt(e.target.value, 10);
        if (spectrogramData.length > 0) {
          drawSpectrogram();
          drawYinPitchChart();
        }
      });
      contrastSlider.addEventListener("input", (e) => {
        settings.contrast = parseFloat(e.target.value);
        if (spectrogramData.length > 0) {
          drawSpectrogram();
          drawYinPitchChart();
        }
      });

      // --- YIN PARAMETER EVENT LISTENERS ---
      function recomputeYin() {
        if (lastAudioBuffer && yinData.length > 0) {
          showYinPitchLoadingOverlay();
          // Use setTimeout to allow overlay to show before heavy computation
          setTimeout(() => {
            yinData = performYinAnalysis(lastAudioBuffer);
            drawYinPitchChart();
            hideYinPitchLoadingOverlay();
          }, 10);
        }
      }

      function showYinPitchLoadingOverlay() {
        yinPitchLoadingOverlay.classList.remove("hidden");
      }

      function hideYinPitchLoadingOverlay() {
        yinPitchLoadingOverlay.classList.add("hidden");
      }

      document
        .getElementById("yinFrameSize")
        .addEventListener("change", (e) => {
          yinParams.frameSize = parseInt(e.target.value, 10);
          recomputeYin();
        });

      document.getElementById("yinHopSize").addEventListener("change", (e) => {
        yinParams.hopSize = parseInt(e.target.value, 10);
        recomputeYin();
      });

      document
        .getElementById("yinThresholdSlider")
        .addEventListener("input", (e) => {
          yinParams.threshold = parseFloat(e.target.value);
          document.getElementById("yinThresholdValue").textContent =
            yinParams.threshold.toFixed(2);
          recomputeYin();
        });

      document
        .getElementById("yinMinFreqSlider")
        .addEventListener("input", (e) => {
          yinParams.minFreq = parseInt(e.target.value, 10);
          document.getElementById("yinMinFreqValue").textContent =
            yinParams.minFreq;
          recomputeYin();
        });

      document
        .getElementById("yinMaxFreqSlider")
        .addEventListener("input", (e) => {
          yinParams.maxFreq = parseInt(e.target.value, 10);
          document.getElementById("yinMaxFreqValue").textContent =
            yinParams.maxFreq;
          recomputeYin();
        });

      document
        .getElementById("yinInterpolation")
        .addEventListener("change", (e) => {
          yinParams.interpolation = e.target.checked;
          recomputeYin();
        });

      // --- UI HELPER FUNCTIONS ---
      function getRecordInstructions() {
        return 'Hold <kbd class="px-2 py-1.5 text-xs font-semibold text-gray-800 bg-gray-100 border border-gray-200 rounded-lg">Space</kbd> to record';
      }
      function getPlaybackInstructions() {
        return 'To <button class="px-4 py-0 bg-blue-800 hover:bg-blue-700 text-gray-300 font-medium rounded-lg transition-colors duration-200" onclick="playLastRecording()">play audio 🔊</button> Press <kbd class="px-2 py-1.5 text-xs font-semibold text-gray-800 bg-gray-100 border border-gray-200 rounded-lg">Enter</kbd>';
      }

      function getDefaultInstructions() {
        return getPlaybackInstructions() + " • " + getRecordInstructions();
      }

      // --- CORE AUDIO FUNCTIONS ---
      async function startRecording() {
        if (isRecording) return;
        isRecording = true;
        audioChunks = [];

        statusDiv.style.backgroundColor = "#ef4444";
        instructions.textContent = "Recording...";

        try {
          // Ensure AudioContext is created by user gesture
          if (!audioContext) {
            audioContext = new (window.AudioContext ||
              window.webkitAudioContext)();
          }
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          mediaRecorder = new MediaRecorder(stream);
          mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
          };
          mediaRecorder.onstop = processAudio;
          mediaRecorder.start();
        } catch (err) {
          console.error("Error accessing microphone:", err);
          instructions.textContent =
            "Microphone access denied. Please allow access and try again.";
          statusDiv.style.backgroundColor = "#d97706";
          isRecording = false;
        }
      }

      function stopRecording() {
        if (!isRecording || !mediaRecorder) return;
        mediaRecorder.stop();

        // Clean up media stream tracks
        if (mediaRecorder.stream) {
          mediaRecorder.stream.getTracks().forEach((track) => track.stop());
        }

        isRecording = false;
        statusDiv.style.backgroundColor = "#3b82f6";
        instructions.textContent = "Analyzing...";
        showYinPitchLoadingOverlay();
      }

      function processAudio() {
        const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
        const reader = new FileReader();
        reader.onload = async (e) => {
          try {
            const audioBuffer = await audioContext.decodeAudioData(
              e.target.result
            );
            // Initialize data arrays (will be filled during spectrogram analysis)
            yinData = [];
            lastAudioBuffer = audioBuffer; // Store for replay

            // Perform YIN analysis
            yinData = performYinAnalysis(audioBuffer);

            hideYinPitchLoadingOverlay();

            analyzeAndDraw(audioBuffer);

            // Auto-play using the same functionality as the play button
            playLastRecording();
          } catch (err) {
            console.error("Error decoding audio data:", err);
            instructions.textContent =
              "Could not process audio. Please try again.";
          }
        };
        reader.readAsArrayBuffer(audioBlob);
      }

      function playAudio(audioBuffer) {
        // Stop any currently playing audio
        if (currentAudioSource) {
          currentAudioSource.stop();
        }

        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(audioContext.destination);

        currentAudioSource = source;
        isPlaying = true;
        playStartTime = audioContext.currentTime;

        // Show progress line
        progressLine.classList.remove("hidden");
        progressLine.style.left = "0%";

        // Start progress tracking
        const duration = audioBuffer.duration;
        const startTime = Date.now();

        const progressInterval = setInterval(() => {
          if (!isPlaying) {
            clearInterval(progressInterval);
            return;
          }

          const elapsed = (Date.now() - startTime) / 1000; // Convert to seconds
          const progress = Math.min((elapsed / duration) * 100, 100);

          progressLine.style.left = progress + "%";

          if (progress >= 100 || elapsed >= duration) {
            clearInterval(progressInterval);
            isPlaying = false;
            currentAudioSource = null;
            progressLine.style.left = "100%";
            // Keep progress line visible briefly after completion
            setTimeout(() => {
              if (!isPlaying) {
                progressLine.classList.add("hidden");
              }
            }, 1000);
          }
        }, 50); // Update every 50ms for smooth animation

        source.onended = () => {
          isPlaying = false;
          currentAudioSource = null;
          // Hide progress line when playback ends
          setTimeout(() => {
            progressLine.classList.add("hidden");
          }, 100);
        };

        source.start(0);
      }

      function playLastRecording() {
        if (lastAudioBuffer && audioContext) {
          playAudio(lastAudioBuffer);
        }
      }

      async function loadPreloadedAudio() {
        try {
          // Show loading indicator
          statusDiv.style.backgroundColor = "#3b82f6";
          instructions.innerHTML =
            '<div class="flex items-center justify-center"><div class="animate-spin rounded-full h-4 w-4 border-b-2 border-blue-300 mr-2"></div>Processing preloaded audio...</div>';

          // Initialize audio context if not already done
          if (!audioContext) {
            audioContext = new (window.AudioContext ||
              window.webkitAudioContext)();
          }

          // Convert base64 data URL to array buffer
          const response = await fetch(PRELOADED_AUDIO_DATA);
          const arrayBuffer = await response.arrayBuffer();

          // Decode audio data
          const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

          // Store as last audio buffer for playback
          lastAudioBuffer = audioBuffer;

          // Initialize data arrays
          yinData = [];

          // Update loading message for YIN analysis
          instructions.innerHTML =
            '<div class="flex items-center justify-center"><div class="animate-spin rounded-full h-4 w-4 border-b-2 border-purple-300 mr-2"></div>Computing YIN pitch analysis...</div>';

          // Perform YIN analysis
          yinData = performYinAnalysis(audioBuffer);

          // Update loading message for spectrogram
          instructions.innerHTML =
            '<div class="flex items-center justify-center"><div class="animate-spin rounded-full h-4 w-4 border-b-2 border-green-300 mr-2"></div>Generating spectrogram...</div>';

          // Analyze and draw visualizations
          analyzeAndDraw(audioBuffer);

          // Update UI to show that audio is loaded
          statusDiv.style.backgroundColor = "#374151";
          instructions.innerHTML =
            "Preloaded audio ready! " + getDefaultInstructions();

          // Show controls and play button
          controls.style.display = "grid";
          playButton.style.display = "flex";
          document
            .getElementById("yinControlsSection")
            .classList.remove("hidden");
        } catch (err) {
          console.error("Error loading preloaded audio:", err);
          instructions.innerHTML =
            "Error loading preloaded audio. " + getRecordInstructions();
          statusDiv.style.backgroundColor = "#d97706";
        }
      }

      function analyzeAndDraw(audioBuffer) {
        const offlineCtx = new OfflineAudioContext(
          audioBuffer.numberOfChannels,
          audioBuffer.length,
          audioBuffer.sampleRate
        );
        const source = offlineCtx.createBufferSource();
        source.buffer = audioBuffer;

        const analyser = offlineCtx.createAnalyser();
        analyser.fftSize = FFT_SIZE; // Use the new higher resolution FFT size
        analyser.smoothingTimeConstant = 0;

        // Decreased buffer size for better time (horizontal) resolution.
        const bufferSize = BUFFER_SIZE;
        const processor = offlineCtx.createScriptProcessor(bufferSize, 1, 1);

        const freqData = new Uint8Array(analyser.frequencyBinCount);
        spectrogramData = [];

        processor.onaudioprocess = (e) => {
          analyser.getByteFrequencyData(freqData);
          spectrogramData.push(new Uint8Array(freqData));
        };

        source.connect(analyser);
        analyser.connect(processor);
        processor.connect(offlineCtx.destination);

        source.start(0);

        offlineCtx
          .startRendering()
          .then(() => {
            console.log(
              `Analysis complete. Got ${spectrogramData.length} time slices.`
            );
            statusDiv.style.backgroundColor = "#374151";
            instructions.innerHTML = getDefaultInstructions();
            controls.style.display = "grid";
            playButton.style.display = "flex";
            document
              .getElementById("yinControlsSection")
              .classList.remove("hidden");

            drawSpectrogram();
            drawYinPitchChart();
          })
          .catch((err) => {
            console.error("Offline rendering failed:", err);
            instructions.textContent = "Error during analysis.";
          });
      }

      function drawSpectrogram() {
        const numSlices = spectrogramData.length;
        if (numSlices === 0) return;

        // --- EDITED FOR FOCUSED VIEW ---
        // Calculate how many frequency bins to show to focus on the vocal range.
        const freqPerBin = audioContext.sampleRate / FFT_SIZE;
        const relevantBins = Math.ceil(MAX_FREQ_HZ / freqPerBin);
        const totalBins = spectrogramData[0].length;
        const finalBinsToDraw = Math.min(relevantBins, totalBins);

        canvas.width = numSlices;
        canvas.height = finalBinsToDraw;

        const imageData = canvasCtx.createImageData(
          canvas.width,
          canvas.height
        );
        const data = imageData.data;

        for (let x = 0; x < canvas.width; x++) {
          for (let y = 0; y < canvas.height; y++) {
            const value = spectrogramData[x][y];
            const color = getColor(value, settings.colorScheme);

            let r =
              settings.contrast * (color[0] - 128) + 128 + settings.brightness;
            let g =
              settings.contrast * (color[1] - 128) + 128 + settings.brightness;
            let b =
              settings.contrast * (color[2] - 128) + 128 + settings.brightness;

            r = Math.max(0, Math.min(255, r));
            g = Math.max(0, Math.min(255, g));
            b = Math.max(0, Math.min(255, b));

            const pixelIndex = ((canvas.height - 1 - y) * canvas.width + x) * 4;
            data[pixelIndex] = r;
            data[pixelIndex + 1] = g;
            data[pixelIndex + 2] = b;
            data[pixelIndex + 3] = 255;
          }
        }
        canvasCtx.putImageData(imageData, 0, 0);
      }

      function drawYinPitchChart() {
        if (yinData.length === 0) return;

        // Set high resolution canvas dimensions to match spectrogram
        const displayWidth = yinPitchCanvas.offsetWidth;
        const displayHeight = yinPitchCanvas.offsetHeight;
        const pixelRatio = window.devicePixelRatio || 1;

        yinPitchCanvas.width = displayWidth * pixelRatio;
        yinPitchCanvas.height = displayHeight * pixelRatio;

        // Scale context to ensure correct drawing operations
        yinPitchCanvasCtx.scale(pixelRatio, pixelRatio);

        // Set CSS size to maintain display size
        yinPitchCanvas.style.width = displayWidth + "px";
        yinPitchCanvas.style.height = displayHeight + "px";

        const ctx = yinPitchCanvasCtx;
        const width = displayWidth;
        const height = displayHeight;

        // Clear canvas with transparent background
        ctx.clearRect(0, 0, width, height);

        // Calculate average YIN data for visualization
        const avgFrame = yinData[Math.floor(yinData.length / 2)];
        if (!avgFrame) return;

        // Update UI indicators
        // const yinThreshold = document.getElementById("yinThreshold");
        // const yinPitchValue = document.getElementById("yinPitchValue");

        const avgPitch =
          yinData.reduce((sum, frame) => sum + frame.pitch, 0) / yinData.length;
        const avgConfidence =
          yinData.reduce((sum, frame) => sum + frame.confidence, 0) /
          yinData.length;

        // yinThreshold.textContent = avgFrame.threshold.toFixed(3);
        // yinPitchValue.textContent =
        //   avgPitch > 0
        //     ? `${Math.round(avgPitch)}Hz (${(avgConfidence * 100).toFixed(0)}%)`
        //     : "No pitch";

        const validPitches = yinData.filter((frame) => frame.pitch > 0);
        if (validPitches.length > 0) {
          const minPitch = Math.min(
            yinParams.minFreq,
            ...validPitches.map((f) => f.pitch)
          );
          const maxPitch = Math.max(...validPitches.map((f) => f.pitch));
          const pitchRange = Math.max(maxPitch - minPitch, 50);

          // Draw pitch line with confidence-based opacity
          ctx.lineWidth = 3;

          let lastValidX = -1;
          let lastValidY = -1;

          for (let i = 0; i < yinData.length; i++) {
            const frame = yinData[i];
            if (frame.pitch > 0) {
              // Map time index to canvas width (matching spectrogram time axis)
              const timeRatio = i / (yinData.length - 1);
              const x = timeRatio * width;

              // Map pitch to independent Y-axis (full canvas height for pitch range)
              const pitchRatio = (frame.pitch - minPitch) / pitchRange;
              const y = height - pitchRatio * height;

              // Color based on confidence with bright, visible colors
              const alpha = Math.max(0.1, frame.confidence);
              const strokeAlpha = 0;

              // Use bright yellow/white for high visibility over spectrogram
              ctx.strokeStyle = `rgba(255, 255, 0, ${strokeAlpha})`;
              ctx.fillStyle = `rgba(255, 255, 255, ${alpha})`;

              // Draw line connecting consecutive valid pitch points
              if (lastValidX >= 0 && lastValidY >= 0) {
                ctx.beginPath();
                ctx.moveTo(lastValidX, lastValidY);
                ctx.lineTo(x, y);
                ctx.stroke();
              }

              // Draw confidence dots with shadow
              ctx.shadowColor = "rgba(0, 0, 0, 0.8)";
              ctx.shadowBlur = 4;
              ctx.shadowOffsetX = 1;
              ctx.shadowOffsetY = 1;

              ctx.beginPath();
              ctx.arc(x, y, 3, 0, 2 * Math.PI);
              ctx.fill();

              // Reset shadow for next elements
              ctx.shadowColor = "transparent";
              ctx.shadowBlur = 0;
              ctx.shadowOffsetX = 0;
              ctx.shadowOffsetY = 0;

              lastValidX = x;
              lastValidY = y;
            } else {
              // Reset line drawing when pitch is invalid
              lastValidX = -1;
              lastValidY = -1;
            }
          }

          // Draw pitch range labels on the overlay
          ctx.fillStyle = "rgba(255, 255, 255, 0.9)";
          ctx.font = "12px Inter";
          ctx.textAlign = "left";
          ctx.fillText(`${Math.round(maxPitch)}Hz`, 5, 20);
          ctx.fillText(`${Math.round(minPitch)}Hz`, 5, height - 10);

          // Draw YIN performance info
          if (yinPerformanceData.frameCount > 0) {
            ctx.fillStyle = "rgba(255, 255, 0, 0.9)";
            ctx.font = "10px Inter";
            ctx.textAlign = "left";
            ctx.fillText(`YIN: ${yinPerformanceData.totalTime.toFixed(0)}ms total`, 5, 35);
            ctx.fillText(`Diff: ${yinPerformanceData.totalDiffTime.toFixed(0)}ms total`, 5, 47);
            ctx.fillText(`Frames: ${yinPerformanceData.frameCount}`, 5, 59);
          }
        } else {
          ctx.fillStyle = "#9CA3AF";
          ctx.font = "14px Inter";
          ctx.textAlign = "center";
          ctx.fillText("No pitch detected", width / 2, height / 2);
        }
      }

    </script>
  </body>
</html>
