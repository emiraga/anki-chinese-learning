import google.generativeai as genai
import json
import os
from urllib.parse import quote
import time
from google.cloud import texttospeech
import random
from datetime import datetime

with open("ai_key.txt") as f:
    genai.configure(api_key=f.read().strip())

CHARS = "ÁöÑ‰∏ÄÊòØ‰∏ç‰∫ÜÂú®‰∫∫ÊúâÊàë‰ªñÈÄôÂÄãÂÄë‰∏≠‰æÜ‰∏äÂ§ßÁÇ∫ÂíåÂúãÂú∞Âà∞‰ª•Ë™™ÊôÇË¶ÅÂ∞±Âá∫ÊúÉÂèØ‰πü‰Ω†Â∞çÁîüËÉΩÂ≠êÈÇ£Âæó‰∏ãËá™‰πãÂπ¥ÈÅé‰ΩúË£°Áî®ÈÅìË°åÊâÄÁÑ∂ÂÆ∂‰∫ãÊàêÊñπÂ§öÂéªÊ≥ïÂ≠∏Â¶ÇÈÉΩÂêåÁèæÁï∂Ê≤íÂãïÈ∫µËµ∑ÁúãÂÆöÂ§©ÂàÜÈÇÑÈÄ≤Â•ΩÂ∞èÂÖ∂‰∫õ‰∏ªÊ®£ÂøÉÂ•πÊú¨ÂâçÈñã‰ΩÜÂõ†Âè™ÂæûÊÉ≥Êó•ËÄÖÊÑèÁÑ°ÂäõÈï∑ÊääÊ©üÂçÅÁ¨¨ÂÖ¨Â∑•ÊòéÁü•‰∏âÈóúÈªûÊ•≠Â§ñÂÖ©È´òÈñìÂïèÂæàÊúÄÁâ©ÊâãÊñáÈ´îÁæéÁõ∏Ë¶ã‰∫åÁ≠âÊàñÊñ∞Â∑±Ë∫´ÊûúË•øÊúàË©±ÂõûÁâπÂÖßËÄÅÁµ¶‰∏ñ‰ΩçÊ¨°ÈñÄÂ∏∏ÂÖàÊµ∑ÊïôÂÖíÊù±ÊØîÊ∞¥ÂêçÁúüËµ∞ÂÖ•ÂπæÂè£Ë™ç‰øÇÊ∞£È°åÊõ¥Âà•ÊâìÂ•≥ÂõõÈõªÂÆâÂ∞ëÊâçÂ§™ÂÜçÂÅöÊé•‰ª∂Ë®àÊúüÂ∏ÇÂ±±Ë®±Ëá≥‰æøÁ©∫È¶¨‰∫îÊõ∏ÈùûËÅΩÁôΩÁïåÂÖâÈõ£ÊÄùÂÆåË∑ØÂçó‰ΩèÁ®ãÂåóÈÇäÂºµÂèñÊãâË¶∫ÂÖ±Â∏´‰ªäÈô¢Ë≠òÂÄôÂ∏∂ÈÅãÊØèËªäË¶™ÊûóÊúçÂø´Ëã±ËøëÊ∫ñÂßãÊÄéÂë¢Âè´Âè∞ÂñÆÂΩ±Â≠óÊÑõÂÇôÂïÜÁôæÈúÄËä±Âüé‰∫ûË´ãÊÅØÁÅ´Ë¶ñË∂äÂÆπÁÖß‰πùÂØ´ÂÖ´ÂóéÂåÖÁâáÊòìÊó©Èô§ÊâæÂêßÂêÉÂøµÂÖ≠ÈÄ±ËºÉÊé®ÊàøÂçäÈªëÂæãË∂≥‰∏ÉËààÂ≠©ÊòüÈü≥Ë∑üÂ∫ïÁ´ôÊØç‰∫¨Á±≥ÂÆ¢ÂØÜÂèãÊ≠¢ÂçÉÁî∑Èå¢Á∂≤ÁÜ±ÂùêËàπÊ®ÇÁêÉÊÄïÊ†°Ëã¶‰πÖÈåØÊôöËÖ¶Ë™∞Âì™Â∞ºÈ©öÂ§úÂàùÂñúÈ£üÂæÖÁøíÊ≠°ÂÅúÊ∏∏ÈæçÂÜ∑Ê¥≤Âè•Êº¢Ë°£ÊÇ®Â™ΩËÆÄÂïäË≤∑Ê≠≤ËëóÁî∞Â∑¶Âè≥‰ªΩÂ°äÈÖíÂ≥∂Âì•ÂØ∂Âºü‰ºØÊÖ¢Ê≠êÂøôÂßê‰ªãËá®‰∫ÆÊ≤ôÈ≠öÁÅ£Ë≤¥ÊúãÁßòË¨ùÈêòÁ¶ÆÈõ®ÈóÜÈ£ØËÑ´ÊóÖÁ≠ÜÁù°Ë≥£Â†ÇÂñùÂúíÂçàÁ∑¥ËÇâÁâõÂ∫óÁà∏Â∫äËøéÂÜ∞Áé©‰ºëÂÖÑË°óÈ†ÅÂßìË™†Êú´Â¶πË™≤ÊáÇÂª≥ÊãúÁ¥πËèúÈñâËå∂Â•∂Áè†ÂÆúÁèçÁæäÈõ∂ËÉ∏ËõãÈõûÊùØÁßüÈ§êÊò®ÊºÇËÖêÈûãÁ≥ñË±¨Ë±ÜÊê≠ËÉñÈ§ìÁ±†ËÅäËÇåÁ¢óÈà¥È£Ω‰πæÁîúÁÅòËá≠ÂæåÈ¥®ÂßäÊ£íÂï°Âô¢Á±ÉÂíñÁ≥ïËæ£Ë∏¢ËòãÊÄ°ÂãøÁÇíÊ≥≥È∫ºÂï§‰ªÄÈù¢Ê§∞ÂÆÉÈÅäÂë®Ëá∫Â¶≥Ë£è"
RANDOM_ORDER_CHARS = ''.join(random.sample(CHARS, len(CHARS)))

SPECIAL_CHARS = None

def setup_credentials():
    """
    Set up Google Cloud credentials
    You need to:
    1. Create a Google Cloud project
    2. Enable Text-to-Speech API
    3. Create a service account and download JSON key
    4. Set GOOGLE_APPLICATION_CREDENTIALS environment variable
    """
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "gcloud_account.json"
    pass

def get_chinese_sentences_and_translations():
    """
    Generate 10 Chinese sentences using restricted vocabulary via API
    Returns JSON with Traditional Chinese sentences and their English translations
    """

    model = genai.GenerativeModel('gemini-2.5-flash-preview-05-20')

    prompt = f"""\
I am learning Traditional Mandarin with focus on Mandarin that is used in Taiwan.
Use TRADITIONAL Chinese characters (ÁπÅÈ´î‰∏≠Êñá) as used in Taiwan.
I want to you generate 10 sentences with characters I have learned already.

Here are traditional characters I learned so far: {CHARS}

Return ONLY a JSON object in this exact format:
{{
    "‰Ω†Â•Ω": "Hello!",
    "Ë¨ùË¨ù": "Thanks",
    "ÊàëÂæàÂ•Ω": "I am fine",
    ...
}}
Make sentences longer, with variety of tenses, past, future, questions, because, therefore, after that, however, but, maybe, perhaps, possibly, if, then etc.
Sometimes include numbers, dates, time, to help me practice numbers too.
Make sure all Chinese text uses Traditional characters and the sentences are suitable for Taiwanese Mandarin learners.
Level of words should be at TOCFL 1 or HSK 2 level.
Do not use any other characters than ones that I have learned!

{"I want to focus on learning: " + SPECIAL_CHARS + " so include " + SPECIAL_CHARS + " more." if SPECIAL_CHARS and len(SPECIAL_CHARS) > 0 else""}
    """

    try:
        response = model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.7,
            )
        )

        # Check if response has content
        if not response.candidates or not response.candidates[0].content.parts:
            print(f"No content returned. Finish reason: {response.candidates[0].finish_reason}")
            raise Exception("No content generated")

        # Extract the response content
        content = response.text.strip()

        # Clean up the response if it has markdown formatting
        if content.startswith('```json'):
            content = content.replace('```json', '').replace('```', '').strip()
        elif content.startswith('```'):
            content = content.replace('```', '').strip()

        # Parse JSON response
        sentences_dict = json.loads(content)

        return sentences_dict, prompt

    except Exception as e:
        print(f"Error calling API: {e}")
        return None, None


def taiwanese_tts(text, output_file="output.mp3", voice_name="cmn-TW-Standard-A", speaking_rate=0.6):
    """
    Convert text to speech using Taiwanese Mandarin voice

    Args:
        text (str): Text to convert (Traditional Chinese characters)
        output_file (str): Output audio file path
        voice_name (str): Voice to use (see available voices below)
    """

    # Initialize the client
    client = texttospeech.TextToSpeechClient()

    # Set the text input
    synthesis_input = texttospeech.SynthesisInput(text=text)

    # Build the voice request
    voice = texttospeech.VoiceSelectionParams(
        language_code="cmn-TW",  # Taiwanese Mandarin
        name=voice_name,
        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE  # or MALE
    )

    # Select the type of audio file
    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        speaking_rate=speaking_rate,  # Speed (0.25 to 4.0)
        pitch=0.0,          # Pitch (-20.0 to 20.0)
        volume_gain_db=0.0  # Volume (-96.0 to 16.0)
    )

    # Perform the text-to-speech request
    response = client.synthesize_speech(
        input=synthesis_input,
        voice=voice,
        audio_config=audio_config
    )

    # Write the response to an audio file
    with open(output_file, "wb") as out:
        out.write(response.audio_content)
        print(f'Output: "{output_file}"')


def main():
    setup_credentials()
    print("Generating Chinese sentences and audio files...")

    sentences_dict, prompt = get_chinese_sentences_and_translations()

    if not sentences_dict:
        print("Failed to get sentences from API")
        return

    print(f"Generated {len(sentences_dict)} Chinese sentences")

    # Create output directory if it doesn't exist
    output_dir = datetime.now().strftime("%Y-%m-%d-%H-%M")
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Save JSON file
    json_filename = os.path.join(output_dir, "chinese_sentences.json")
    with open(json_filename, 'w', encoding='utf-8') as f:
        json.dump(sentences_dict, f, ensure_ascii=False, indent=2)
    print(f"JSON saved: {json_filename}")

    # Generate audio files for each sentence
    audio_files = []
    voice_name = "cmn-TW-Standard-C"
    speaking_rate = 0.6
    skipped_sentences = {}

    for i, (chinese, english) in enumerate(sentences_dict.items(), 1):
        print(f"\nProcessing {i}/{len(sentences_dict)}:")
        warning = False;
        for c in chinese:
            if c == "„ÄÇ" or c == "Ôºü" or c == "Ôºå" or c == "ÔºÅ":
                continue
            if c not in CHARS:
                skipped_sentences[chinese] = {"missing_char": c, "english":  english}
                print("warning, foreign char: " + c)
                warning = True
                break

        if warning:
            continue

        # Create filename (sanitize Chinese characters for filename)
        safe_filename = f"sentence_{i:02d}.mp3"
        audio_path = os.path.join(output_dir, safe_filename)

        # Generate TTS
        taiwanese_tts(chinese, audio_path, voice_name=voice_name, speaking_rate=speaking_rate)
        audio_files.append({
            "chinese": chinese,
            "english": english,
            "audio_file": safe_filename,
            "pinyin": ""  # You could add pinyin here if needed
        })

        # Small delay to be respectful to the TTS service
        time.sleep(0.5)

    # Save detailed output with audio file references
    detailed_output = {
        "voice_name": voice_name,
        "speaking_rate": speaking_rate,
        "sentences": sentences_dict,
        "audio_files": audio_files,
        "total_count": len(sentences_dict),
        "output_directory": output_dir,
        "skipped_sentences": skipped_sentences,
        "characters": CHARS,
        "focus_on_chars": SPECIAL_CHARS or "",
        "prompt": prompt,
    }

    detailed_filename = os.path.join(output_dir, "detailed_output.json")
    with open(detailed_filename, 'w', encoding='utf-8') as f:
        json.dump(detailed_output, f, ensure_ascii=False, indent=2)

    with open(os.path.join(output_dir, "study.txt"), "w", encoding='utf-8') as f:
        f.write('\n' * 35)
        for file in audio_files:
            f.write(file["audio_file"] + "\n\n")
            f.write('\n'.join(x for x in file["chinese"]) + '\n\n')
            f.write(file["chinese"] + '\n\n')
            f.write(file["english"] + "\n\n")

    print(f"\n‚úÖ (Complete!)")
    print(f"üìÅ Files saved in: {output_dir}/")
    print(f"üìÑ JSON: chinese_sentences.json")
    print(f"üìÑ TXT: study.txt")
    print(f"üìÑ Detailed: detailed_output.json")
    print(f"üîä Audio files: {len(audio_files)} MP3 files")


def list_taiwanese_voices():
    """List all available Taiwanese Mandarin voices"""
    client = texttospeech.TextToSpeechClient()

    # Performs the list voices request
    voices = client.list_voices()

    print("List all available Taiwanese Mandarin voices:")
    for voice in voices.voices:
        if "cmn-TW" in voice.language_codes:
            print(f"voice name: {voice.name}")
            print(f"language code: {', '.join(voice.language_codes)}")
            print(f"gender: {voice.ssml_gender.name}")
            print(f"sample rate: {voice.natural_sample_rate_hertz}")
            print("-" * 40)

if __name__ == "__main__":
    main()
