<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tone Analyzer for Mandarin Practice</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
      }
      /* Style for the canvas to make it responsive and sharp */
      canvas {
        width: 100%;
        height: 300px;
        background-color: #111827; /* bg-gray-900 */
        border-radius: 0.5rem;
        image-rendering: -moz-crisp-edges;
        image-rendering: -webkit-crisp-edges;
        image-rendering: pixelated;
        image-rendering: crisp-edges;
      }
      /* Custom styles for range sliders */
      input[type="range"] {
        -webkit-appearance: none;
        appearance: none;
        width: 100%;
        height: 8px;
        background: #4b5563; /* bg-gray-600 */
        border-radius: 5px;
        outline: none;
        opacity: 0.7;
        transition: opacity 0.2s;
      }
      input[type="range"]:hover {
        opacity: 1;
      }
      input[type="range"]::-webkit-slider-thumb {
        -webkit-appearance: none;
        appearance: none;
        width: 20px;
        height: 20px;
        background: #3b82f6; /* bg-blue-500 */
        cursor: pointer;
        border-radius: 50%;
      }
      input[type="range"]::-moz-range-thumb {
        width: 20px;
        height: 20px;
        background: #3b82f6; /* bg-blue-500 */
        cursor: pointer;
        border-radius: 50%;
      }
    </style>
  </head>
  <body
    class="bg-gray-800 text-gray-200 flex flex-col items-center justify-center min-h-screen p-4"
  >
    <div class="w-full max-w-4xl mx-auto">
      <div class="text-center mb-6">
        <h1 class="text-3xl md:text-4xl font-bold text-white">Tone Analyzer</h1>
        <p class="text-lg text-gray-400 mt-2">
          For practicing Mandarin Chinese pronunciation
        </p>
      </div>

      <!-- Status Message -->
      <div
        id="status"
        class="text-center mb-4 p-3 rounded-lg bg-gray-700 transition-all duration-300"
      >
        <p id="instructions" class="text-lg font-medium text-blue-300">
          Hold the
          <kbd
            class="px-2 py-1.5 text-xs font-semibold text-gray-800 bg-gray-100 border border-gray-200 rounded-lg"
            >Space</kbd
          >
          key to record
        </p>
      </div>

      <!-- Spectrogram Canvas -->
      <div class="w-full bg-gray-900 rounded-lg shadow-lg p-2">
        <canvas id="spectrogramCanvas"></canvas>
      </div>

      <!-- UI Controls -->
      <div
        id="controls"
        class="mt-6 grid grid-cols-1 md:grid-cols-3 gap-6 bg-gray-700/50 p-6 rounded-lg"
      >
        <div>
          <label
            for="colorScheme"
            class="block mb-2 text-sm font-medium text-gray-300"
            >Color Scheme</label
          >
          <select
            id="colorScheme"
            class="bg-gray-600 border border-gray-500 text-white text-sm rounded-lg focus:ring-blue-500 focus:border-blue-500 block w-full p-2.5"
          >
            <option value="viridis">Viridis</option>
            <option value="plasma">Plasma</option>
            <option value="hot">Hot</option>
            <option value="grayscale">Grayscale</option>
          </select>
        </div>
        <div>
          <label
            for="brightness"
            class="block mb-2 text-sm font-medium text-gray-300"
            >Brightness</label
          >
          <input
            type="range"
            id="brightness"
            min="-100"
            max="100"
            value="0"
            class="w-full"
          />
        </div>
        <div>
          <label
            for="contrast"
            class="block mb-2 text-sm font-medium text-gray-300"
            >Contrast</label
          >
          <input
            type="range"
            id="contrast"
            min="0"
            max="3"
            value="1"
            step="0.1"
            class="w-full"
          />
        </div>
      </div>
    </div>

    <script>
      // DOM Elements
      const instructions = document.getElementById("instructions");
      const statusDiv = document.getElementById("status");
      const canvas = document.getElementById("spectrogramCanvas");
      const canvasCtx = canvas.getContext("2d");
      const controls = document.getElementById("controls");
      const colorSchemeSelect = document.getElementById("colorScheme");
      const brightnessSlider = document.getElementById("brightness");
      const contrastSlider = document.getElementById("contrast");

      // Audio & State Variables
      let audioContext;
      let mediaRecorder;
      let isRecording = false;
      let audioChunks = [];
      let spectrogramData = [];

      // Visualization Settings
      let settings = {
        colorScheme: "viridis",
        brightness: 0,
        contrast: 1,
      };

      // --- ANALYSIS CONSTANTS (EDITED FOR HIGHER RESOLUTION) ---
      // Increased FFT_SIZE for better frequency (vertical) resolution.
      const FFT_SIZE = 4096 * 2;
      // The maximum frequency (in Hz) to display. This focuses the view on the vocal range.
      const MAX_FREQ_HZ = 1300;
      // is about how often we do the analysis. The system collects audio into a buffer, and every time the buffer is full, it runs the analysis.
      const BUFFER_SIZE = 256;

      // --- COLOR MAPS ---
      const COLOR_MAPS = {
        viridis: [
          [68, 1, 84],
          [72, 40, 120],
          [62, 74, 137],
          [49, 104, 142],
          [38, 130, 142],
          [31, 158, 137],
          [53, 183, 121],
          [109, 205, 89],
          [180, 222, 44],
          [253, 231, 37],
        ],
        plasma: [
          [13, 8, 135],
          [72, 1, 163],
          [120, 1, 168],
          [163, 29, 151],
          [201, 62, 122],
          [230, 99, 90],
          [249, 139, 64],
          [254, 183, 43],
          [240, 226, 33],
        ],
        hot: [
          [0, 0, 0],
          [255, 0, 0],
          [255, 255, 0],
          [255, 255, 255],
        ],
        grayscale: [
          [0, 0, 0],
          [255, 255, 255],
        ],
      };

      function interpolateColor(c1, c2, factor) {
        const result = c1.slice();
        for (let i = 0; i < 3; i++) {
          result[i] = Math.round(result[i] + factor * (c2[i] - result[i]));
        }
        return result;
      }

      function getColor(value, schemeName) {
        const map = COLOR_MAPS[schemeName];
        const scaledValue = (value / 255) * (map.length - 1);
        const colorIndex = Math.floor(scaledValue);
        const factor = scaledValue - colorIndex;

        if (colorIndex >= map.length - 1) {
          return map[map.length - 1];
        }
        return interpolateColor(map[colorIndex], map[colorIndex + 1], factor);
      }

      // --- EVENT LISTENERS ---
      window.addEventListener("load", () => {
        controls.style.display = "none";
      });

      document.addEventListener("keydown", (e) => {
        if (e.code === "Space" && !isRecording) {
          e.preventDefault();
          startRecording();
        }
      });

      document.addEventListener("keyup", (e) => {
        if (e.code === "Space" && isRecording) {
          e.preventDefault();
          stopRecording();
        }
      });

      colorSchemeSelect.addEventListener("change", (e) => {
        settings.colorScheme = e.target.value;
        if (spectrogramData.length > 0) drawSpectrogram();
      });
      brightnessSlider.addEventListener("input", (e) => {
        settings.brightness = parseInt(e.target.value, 10);
        if (spectrogramData.length > 0) drawSpectrogram();
      });
      contrastSlider.addEventListener("input", (e) => {
        settings.contrast = parseFloat(e.target.value);
        if (spectrogramData.length > 0) drawSpectrogram();
      });

      // --- CORE AUDIO FUNCTIONS ---
      async function startRecording() {
        if (isRecording) return;
        isRecording = true;
        audioChunks = [];

        statusDiv.classList.remove("bg-gray-700");
        statusDiv.classList.add("bg-red-500");
        instructions.textContent = "Recording...";

        try {
          // Ensure AudioContext is created by user gesture
          if (!audioContext) {
            audioContext = new (window.AudioContext ||
              window.webkitAudioContext)();
          }
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          mediaRecorder = new MediaRecorder(stream);
          mediaRecorder.ondataavailable = (event) => {
            audioChunks.push(event.data);
          };
          mediaRecorder.onstop = processAudio;
          mediaRecorder.start();
        } catch (err) {
          console.error("Error accessing microphone:", err);
          instructions.textContent =
            "Microphone access denied. Please allow access and try again.";
          statusDiv.classList.remove("bg-red-500");
          statusDiv.classList.add("bg-yellow-600");
          isRecording = false;
        }
      }

      function stopRecording() {
        if (!isRecording || !mediaRecorder) return;
        mediaRecorder.stop();
        
        // Clean up media stream tracks
        if (mediaRecorder.stream) {
          mediaRecorder.stream.getTracks().forEach(track => track.stop());
        }
        
        isRecording = false;
        statusDiv.classList.remove("bg-red-500");
        statusDiv.classList.add("bg-blue-500");
        instructions.textContent = "Analyzing...";
      }

      function processAudio() {
        const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
        const reader = new FileReader();
        reader.onload = async (e) => {
          try {
            const audioBuffer = await audioContext.decodeAudioData(
              e.target.result
            );
            analyzeAndDraw(audioBuffer);
            playAudio(audioBuffer);
          } catch (err) {
            console.error("Error decoding audio data:", err);
            instructions.textContent =
              "Could not process audio. Please try again.";
          }
        };
        reader.readAsArrayBuffer(audioBlob);
      }

      function playAudio(audioBuffer) {
        const source = audioContext.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(audioContext.destination);
        source.start(0);
      }

      function analyzeAndDraw(audioBuffer) {
        const offlineCtx = new OfflineAudioContext(
          audioBuffer.numberOfChannels,
          audioBuffer.length,
          audioBuffer.sampleRate
        );
        const source = offlineCtx.createBufferSource();
        source.buffer = audioBuffer;

        const analyser = offlineCtx.createAnalyser();
        analyser.fftSize = FFT_SIZE; // Use the new higher resolution FFT size
        analyser.smoothingTimeConstant = 0;

        // Decreased buffer size for better time (horizontal) resolution.
        const bufferSize = BUFFER_SIZE;
        const processor = offlineCtx.createScriptProcessor(bufferSize, 1, 1);

        const freqData = new Uint8Array(analyser.frequencyBinCount);
        spectrogramData = [];

        processor.onaudioprocess = () => {
          analyser.getByteFrequencyData(freqData);
          spectrogramData.push(new Uint8Array(freqData));
        };

        source.connect(analyser);
        analyser.connect(processor);
        processor.connect(offlineCtx.destination);

        source.start(0);

        offlineCtx
          .startRendering()
          .then(() => {
            console.log(
              `Analysis complete. Got ${spectrogramData.length} time slices.`
            );
            statusDiv.classList.remove("bg-blue-500");
            statusDiv.classList.add("bg-gray-700");
            instructions.innerHTML =
              'Hold the <kbd class="px-2 py-1.5 text-xs font-semibold text-gray-800 bg-gray-100 border border-gray-200 rounded-lg">Space</kbd> key to record';
            controls.style.display = "grid";
            drawSpectrogram();
          })
          .catch((err) => {
            console.error("Offline rendering failed:", err);
            instructions.textContent = "Error during analysis.";
          });
      }

      function drawSpectrogram() {
        const numSlices = spectrogramData.length;
        if (numSlices === 0) return;

        // --- EDITED FOR FOCUSED VIEW ---
        // Calculate how many frequency bins to show to focus on the vocal range.
        const freqPerBin = audioContext.sampleRate / FFT_SIZE;
        const relevantBins = Math.ceil(MAX_FREQ_HZ / freqPerBin);
        const totalBins = spectrogramData[0].length;
        const finalBinsToDraw = Math.min(relevantBins, totalBins);

        canvas.width = numSlices;
        canvas.height = finalBinsToDraw;

        const imageData = canvasCtx.createImageData(
          canvas.width,
          canvas.height
        );
        const data = imageData.data;

        for (let x = 0; x < canvas.width; x++) {
          for (let y = 0; y < canvas.height; y++) {
            const value = spectrogramData[x][y];
            const color = getColor(value, settings.colorScheme);

            let r =
              settings.contrast * (color[0] - 128) + 128 + settings.brightness;
            let g =
              settings.contrast * (color[1] - 128) + 128 + settings.brightness;
            let b =
              settings.contrast * (color[2] - 128) + 128 + settings.brightness;

            r = Math.max(0, Math.min(255, r));
            g = Math.max(0, Math.min(255, g));
            b = Math.max(0, Math.min(255, b));

            const pixelIndex = ((canvas.height - 1 - y) * canvas.width + x) * 4;
            data[pixelIndex] = r;
            data[pixelIndex + 1] = g;
            data[pixelIndex + 2] = b;
            data[pixelIndex + 3] = 255;
          }
        }
        canvasCtx.putImageData(imageData, 0, 0);
      }
    </script>
  </body>
</html>
